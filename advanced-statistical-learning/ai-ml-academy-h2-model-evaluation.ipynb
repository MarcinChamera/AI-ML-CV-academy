{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-08T11:03:11.619900Z","iopub.execute_input":"2022-09-08T11:03:11.621362Z","iopub.status.idle":"2022-09-08T11:03:11.647894Z","shell.execute_reply.started":"2022-09-08T11:03:11.621253Z","shell.execute_reply":"2022-09-08T11:03:11.647340Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Homework description\n\n1. Take data from house pricing (kaggle)\n2. Prepare metrics. Using bootstrap fit K=10 models with different hyper parameters\n    - fit K linear regressions per several hyperparameters\n    - K gradient bostings per several hyperparameters\n    - K neural networks per several hyperparameters\n1. For each model and hyperparameter setup estimate confidence interval.\n2. Create a rate dashboard using avg metrics (train or validation avg metric). Take top-2 models and answer questions:\n    - do for 1-st model train and validation intervals intersect each other?\n    - do for 1-st and 2-nd model tr. intervals intersect each other?\n    - do for 1-st and 2-dn mode val. intervals intersect each other?\n1. Apply t-test to 1-st model (train-validation metrics). Apply same test for 1-st and 2-nd train metrics (for validation too)\n2. What model is the best? Does itâ€™s CI intersect other CI?\n","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-09-08T11:06:34.584514Z","iopub.execute_input":"2022-09-08T11:06:34.584870Z","iopub.status.idle":"2022-09-08T11:06:34.628914Z","shell.execute_reply.started":"2022-09-08T11:06:34.584842Z","shell.execute_reply":"2022-09-08T11:06:34.627910Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Features: simple, only floats and ints (data preprocessing was not part of this homework - and any other homework from this module of academy)","metadata":{}},{"cell_type":"code","source":"numeric_columns = [i for i, j in zip(train_data.columns, train_data.dtypes) if j in [np.int64, np.float64] and i not in ['SalePrice', 'Id']]\nx_train = train_data[numeric_columns].fillna(-1)\nx_test = test_data[numeric_columns].fillna(-1)","metadata":{"execution":{"iopub.status.busy":"2022-09-08T11:06:36.028723Z","iopub.execute_input":"2022-09-08T11:06:36.029048Z","iopub.status.idle":"2022-09-08T11:06:36.038326Z","shell.execute_reply.started":"2022-09-08T11:06:36.029024Z","shell.execute_reply":"2022-09-08T11:06:36.037495Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ny_train = np.log(train_data['SalePrice'])\n\n_ = plt.hist(y_train)","metadata":{"execution":{"iopub.status.busy":"2022-09-08T11:06:37.252526Z","iopub.execute_input":"2022-09-08T11:06:37.252907Z","iopub.status.idle":"2022-09-08T11:06:37.403612Z","shell.execute_reply.started":"2022-09-08T11:06:37.252873Z","shell.execute_reply":"2022-09-08T11:06:37.402663Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Why target was logarithmized?\nBecause without logarithm, in test stage, for parametric models like linear regression or neural network, sale prices (target) will be smaller than 0","metadata":{}},{"cell_type":"code","source":"def rmse(a, b):\n    return ((a - b) ** 2).mean() ** 0.5","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:10:57.737357Z","iopub.execute_input":"2022-08-22T12:10:57.737745Z","iopub.status.idle":"2022-08-22T12:10:57.744836Z","shell.execute_reply.started":"2022-08-22T12:10:57.737711Z","shell.execute_reply":"2022-08-22T12:10:57.743688Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**Linear Regression (Elastic Net)**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import ElasticNet\nfrom tqdm import tqdm\n\nK = 10\n\npreds_train = []\npreds_validation = []\n\nlr_metrics = []\n\nhyperparameters = [\n    [1, 0.5],\n    [1, 1],\n    [1, 0],\n    [1, 0.25],\n    [1, 0.75],\n    [10, 0.5],\n    [10, 0.25],\n    [10, 0.75],\n    [10, 0],\n    [10, 1]\n]\n\nfor hyperparameters_i in tqdm(hyperparameters):\n    for k in range(K):\n        x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, shuffle=True, random_state=k)\n\n        lr = ElasticNet(alpha=hyperparameters_i[0], l1_ratio=hyperparameters_i[1]).fit(x_tr, y_tr)\n\n        preds_tr = lr.predict(x_tr)\n        preds_val = lr.predict(x_val)\n\n        preds_train.append(preds_tr)\n        preds_validation.append(preds_val)\n\n        train_mse = rmse(preds_tr, y_tr)\n        val_mse = rmse(preds_val, y_val)\n\n        lr_metrics.append({\n            'algorithm' : f'ElasticNet: alpha={hyperparameters_i[0]}, l1_ratio={hyperparameters_i[1]}',\n            'train_mse' : train_mse,\n            'val_mse' : val_mse,\n        })","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:10:57.746530Z","iopub.execute_input":"2022-08-22T12:10:57.747256Z","iopub.status.idle":"2022-08-22T12:11:04.700875Z","shell.execute_reply.started":"2022-08-22T12:10:57.747210Z","shell.execute_reply":"2022-08-22T12:11:04.699595Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"lr_metrics_df = pd.DataFrame(lr_metrics)\nlr_metrics_df.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:11:04.706390Z","iopub.execute_input":"2022-08-22T12:11:04.708180Z","iopub.status.idle":"2022-08-22T12:11:04.747221Z","shell.execute_reply.started":"2022-08-22T12:11:04.708130Z","shell.execute_reply":"2022-08-22T12:11:04.745903Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"grouped_lr_metrics_df = lr_metrics_df.groupby(['algorithm']).agg(['mean', 'std', 'count'])\ngrouped_lr_metrics_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:11:04.750291Z","iopub.execute_input":"2022-08-22T12:11:04.751768Z","iopub.status.idle":"2022-08-22T12:11:04.806457Z","shell.execute_reply.started":"2022-08-22T12:11:04.751718Z","shell.execute_reply":"2022-08-22T12:11:04.805266Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import norm\na = 0.05\n# 95% confident interval\nxi = norm.ppf(1 - a / 2)\n\nlr_confidence_intervals_train = []\nlr_confidence_intervals_val = []\n\nfor i in range(len(hyperparameters)):\n    lr_confidence_intervals_train.append(\n        np.array([-1, 1]) * xi * grouped_lr_metrics_df.iloc[i]['train_mse']['std'] / grouped_lr_metrics_df.iloc[i]['train_mse']['count'] ** 0.5 + grouped_lr_metrics_df.iloc[i]['train_mse']['mean']\n    )\n\n    lr_confidence_intervals_val.append(\n        np.array([-1, 1]) * xi * grouped_lr_metrics_df.iloc[i]['val_mse']['std'] / grouped_lr_metrics_df.iloc[i]['val_mse']['count'] ** 0.5 + grouped_lr_metrics_df.iloc[i]['val_mse']['mean']\n    )","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:11:04.808464Z","iopub.execute_input":"2022-08-22T12:11:04.809306Z","iopub.status.idle":"2022-08-22T12:11:04.843083Z","shell.execute_reply.started":"2022-08-22T12:11:04.809259Z","shell.execute_reply":"2022-08-22T12:11:04.841678Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"lr_confidence_intervals_train","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:11:04.844482Z","iopub.execute_input":"2022-08-22T12:11:04.844974Z","iopub.status.idle":"2022-08-22T12:11:04.856482Z","shell.execute_reply.started":"2022-08-22T12:11:04.844939Z","shell.execute_reply":"2022-08-22T12:11:04.855334Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"lr_confidence_intervals_val","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:11:04.857890Z","iopub.execute_input":"2022-08-22T12:11:04.859110Z","iopub.status.idle":"2022-08-22T12:11:04.871595Z","shell.execute_reply.started":"2022-08-22T12:11:04.859072Z","shell.execute_reply":"2022-08-22T12:11:04.870511Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"grouped_lr_metrics_df['conf_inter_train_left'] = [lr_confidence_intervals_train_el[0] for lr_confidence_intervals_train_el in lr_confidence_intervals_train]\ngrouped_lr_metrics_df['conf_inter_train_right'] = [lr_confidence_intervals_train_el[1] for lr_confidence_intervals_train_el in lr_confidence_intervals_train]\ngrouped_lr_metrics_df['conf_inter_val_left'] = [lr_confidence_intervals_val_el[0] for lr_confidence_intervals_val_el in lr_confidence_intervals_val]\ngrouped_lr_metrics_df['conf_inter_val_right'] = [lr_confidence_intervals_val_el[1] for lr_confidence_intervals_val_el in lr_confidence_intervals_val]","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:11:04.872788Z","iopub.execute_input":"2022-08-22T12:11:04.873572Z","iopub.status.idle":"2022-08-22T12:11:04.890054Z","shell.execute_reply.started":"2022-08-22T12:11:04.873507Z","shell.execute_reply":"2022-08-22T12:11:04.888414Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Confidence intervals help to estimate quality of metrics and build statistical tests","metadata":{}},{"cell_type":"code","source":"grouped_lr_metrics_df","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:11:04.893856Z","iopub.execute_input":"2022-08-22T12:11:04.894194Z","iopub.status.idle":"2022-08-22T12:11:04.915853Z","shell.execute_reply.started":"2022-08-22T12:11:04.894162Z","shell.execute_reply":"2022-08-22T12:11:04.915026Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**Gradient Boosting**","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgbm\n\npreds_train = []\npreds_validation = []\n\ngb_metrics = []\n\nhyperparameters = [\n    [1000, 3],\n    [2000, 3],\n    [1000, 4],\n    [2000, 4],\n    [1000, 5],\n    [2000, 5],\n    [1000, 6],\n    [2000, 6],\n    [1000, 7],\n    [2000, 7]\n]\n\nfor hyperparameters_i in tqdm(hyperparameters):\n    for k in range(K):\n        x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, shuffle=True, random_state=k)\n\n        lgbm_model = lgbm.LGBMRegressor(n_estimators=hyperparameters_i[0], max_depth=hyperparameters_i[1]).fit(x_tr, y_tr)\n\n        preds_tr = lgbm_model.predict(x_tr)\n        preds_val = lgbm_model.predict(x_val)\n\n        preds_train.append(preds_tr)\n        preds_validation.append(preds_val)\n\n        train_mse = rmse(preds_tr, y_tr)\n        val_mse = rmse(preds_val, y_val)\n\n        gb_metrics.append({\n            'algorithm' : f'LightGBM: n_estimators={hyperparameters_i[0]}, max_depth={hyperparameters_i[1]}',\n            'train_mse' : train_mse,\n            'val_mse' : val_mse,\n        })","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:11:04.917112Z","iopub.execute_input":"2022-08-22T12:11:04.917896Z","iopub.status.idle":"2022-08-22T12:13:00.637393Z","shell.execute_reply.started":"2022-08-22T12:11:04.917862Z","shell.execute_reply":"2022-08-22T12:13:00.636148Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"gb_metrics_df = pd.DataFrame(gb_metrics)\ngb_metrics_df.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:13:00.639135Z","iopub.execute_input":"2022-08-22T12:13:00.639840Z","iopub.status.idle":"2022-08-22T12:13:00.655831Z","shell.execute_reply.started":"2022-08-22T12:13:00.639791Z","shell.execute_reply":"2022-08-22T12:13:00.654294Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"grouped_gb_metrics_df = gb_metrics_df.groupby(['algorithm']).agg(['mean', 'std', 'count'])\ngrouped_gb_metrics_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:13:00.657284Z","iopub.execute_input":"2022-08-22T12:13:00.657660Z","iopub.status.idle":"2022-08-22T12:13:00.683807Z","shell.execute_reply.started":"2022-08-22T12:13:00.657625Z","shell.execute_reply":"2022-08-22T12:13:00.682833Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"gb_confidence_intervals_train = []\ngb_confidence_intervals_val = []\n\nfor i in range(len(hyperparameters)):\n    gb_confidence_intervals_train.append(\n        np.array([-1, 1]) * xi * grouped_gb_metrics_df.iloc[i]['train_mse']['std'] / grouped_gb_metrics_df.iloc[i]['train_mse']['count'] ** 0.5 + grouped_gb_metrics_df.iloc[i]['train_mse']['mean']\n    )\n\n    gb_confidence_intervals_val.append(\n        np.array([-1, 1]) * xi * grouped_gb_metrics_df.iloc[i]['val_mse']['std'] / grouped_gb_metrics_df.iloc[i]['val_mse']['count'] ** 0.5 + grouped_gb_metrics_df.iloc[i]['val_mse']['mean']\n    )","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:13:00.684837Z","iopub.execute_input":"2022-08-22T12:13:00.685259Z","iopub.status.idle":"2022-08-22T12:13:00.719773Z","shell.execute_reply.started":"2022-08-22T12:13:00.685219Z","shell.execute_reply":"2022-08-22T12:13:00.718409Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"grouped_gb_metrics_df['conf_inter_train_left'] = [gb_confidence_intervals_train_el[0] for gb_confidence_intervals_train_el in gb_confidence_intervals_train]\ngrouped_gb_metrics_df['conf_inter_train_right'] = [gb_confidence_intervals_train_el[1] for gb_confidence_intervals_train_el in gb_confidence_intervals_train]\ngrouped_gb_metrics_df['conf_inter_val_left'] = [gb_confidence_intervals_val_el[0] for gb_confidence_intervals_val_el in gb_confidence_intervals_val]\ngrouped_gb_metrics_df['conf_inter_val_right'] = [gb_confidence_intervals_val_el[1] for gb_confidence_intervals_val_el in gb_confidence_intervals_val]\n\ngrouped_gb_metrics_df","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:13:00.721263Z","iopub.execute_input":"2022-08-22T12:13:00.721681Z","iopub.status.idle":"2022-08-22T12:13:00.750936Z","shell.execute_reply.started":"2022-08-22T12:13:00.721644Z","shell.execute_reply":"2022-08-22T12:13:00.749629Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Simple MLPRegressor, nothing more advanced like Keras, just to meet requirements - small amount of iterations & layers to don't spend too much time on training","metadata":{}},{"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\n\npreds_train = []\npreds_validation = []\n\nmlp_metrics = []\n\nMAX_ITER = 1000\n\nhyperparameters = [\n    (2000, 2000),\n    (2000, 2000, 2000),\n]\n\nfor hyperparameters_i in hyperparameters:\n    for k in tqdm(range(K)):\n        x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, shuffle=True, random_state=k)\n\n        mlp_model = MLPRegressor(hidden_layer_sizes=hyperparameters_i,max_iter=MAX_ITER).fit(x_tr, y_tr)\n    \n        preds_tr = mlp_model.predict(x_tr)\n        preds_val = mlp_model.predict(x_val)\n\n        preds_train.append(preds_tr)\n        preds_validation.append(preds_val)\n\n        train_mse = rmse(preds_tr, y_tr)\n        val_mse = rmse(preds_val, y_val)\n\n        mlp_metrics.append({\n            'algorithm' : f'MLPRegressor: hidden_layer_sizes={hyperparameters_i}, max_iter={MAX_ITER}',\n            'train_mse' : train_mse,\n            'val_mse' : val_mse,\n        })","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:13:00.752584Z","iopub.execute_input":"2022-08-22T12:13:00.753512Z","iopub.status.idle":"2022-08-22T12:38:33.681606Z","shell.execute_reply.started":"2022-08-22T12:13:00.753474Z","shell.execute_reply":"2022-08-22T12:38:33.680388Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"mlp_metrics_df = pd.DataFrame(mlp_metrics)\nmlp_metrics_df.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:38:33.683066Z","iopub.execute_input":"2022-08-22T12:38:33.688797Z","iopub.status.idle":"2022-08-22T12:38:33.712522Z","shell.execute_reply.started":"2022-08-22T12:38:33.688739Z","shell.execute_reply":"2022-08-22T12:38:33.711276Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"grouped_mlp_metrics_df = mlp_metrics_df.groupby(['algorithm']).agg(['mean', 'std', 'count'])\ngrouped_mlp_metrics_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:39:12.603432Z","iopub.execute_input":"2022-08-22T12:39:12.603993Z","iopub.status.idle":"2022-08-22T12:39:12.630881Z","shell.execute_reply.started":"2022-08-22T12:39:12.603944Z","shell.execute_reply":"2022-08-22T12:39:12.629710Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"mlp_confidence_intervals_train = []\nmlp_confidence_intervals_val = []\n\nfor i in range(len(hyperparameters)):\n    mlp_confidence_intervals_train.append(\n        np.array([-1, 1]) * xi * grouped_mlp_metrics_df.iloc[i]['train_mse']['std'] / grouped_mlp_metrics_df.iloc[i]['train_mse']['count'] ** 0.5 + grouped_mlp_metrics_df.iloc[i]['train_mse']['mean']\n    )\n\n    mlp_confidence_intervals_val.append(\n        np.array([-1, 1]) * xi * grouped_mlp_metrics_df.iloc[i]['val_mse']['std'] / grouped_mlp_metrics_df.iloc[i]['val_mse']['count'] ** 0.5 + grouped_mlp_metrics_df.iloc[i]['val_mse']['mean']\n    )","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:39:17.478224Z","iopub.execute_input":"2022-08-22T12:39:17.478847Z","iopub.status.idle":"2022-08-22T12:39:17.492074Z","shell.execute_reply.started":"2022-08-22T12:39:17.478811Z","shell.execute_reply":"2022-08-22T12:39:17.490978Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"grouped_mlp_metrics_df['conf_inter_train_left'] = [mlp_confidence_intervals_train_el[0] for mlp_confidence_intervals_train_el in mlp_confidence_intervals_train]\ngrouped_mlp_metrics_df['conf_inter_train_right'] = [mlp_confidence_intervals_train_el[1] for mlp_confidence_intervals_train_el in mlp_confidence_intervals_train]\ngrouped_mlp_metrics_df['conf_inter_val_left'] = [mlp_confidence_intervals_val_el[0] for mlp_confidence_intervals_val_el in mlp_confidence_intervals_val]\ngrouped_mlp_metrics_df['conf_inter_val_right'] = [mlp_confidence_intervals_val_el[1] for mlp_confidence_intervals_val_el in mlp_confidence_intervals_val]\n\ngrouped_mlp_metrics_df","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:44:12.139910Z","iopub.execute_input":"2022-08-22T12:44:12.140329Z","iopub.status.idle":"2022-08-22T12:44:12.167130Z","shell.execute_reply.started":"2022-08-22T12:44:12.140294Z","shell.execute_reply":"2022-08-22T12:44:12.165912Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"grouped_metrics_df = pd.concat([grouped_lr_metrics_df, grouped_gb_metrics_df, grouped_mlp_metrics_df], axis=0)\ngrouped_metrics_df","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:44:41.517032Z","iopub.execute_input":"2022-08-22T12:44:41.517458Z","iopub.status.idle":"2022-08-22T12:44:41.546389Z","shell.execute_reply.started":"2022-08-22T12:44:41.517422Z","shell.execute_reply":"2022-08-22T12:44:41.545252Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"sorted_metrics_df = grouped_metrics_df.sort_values(by=('val_mse', 'mean'))\nsorted_metrics_df","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:44:45.562456Z","iopub.execute_input":"2022-08-22T12:44:45.562868Z","iopub.status.idle":"2022-08-22T12:44:45.591818Z","shell.execute_reply.started":"2022-08-22T12:44:45.562833Z","shell.execute_reply":"2022-08-22T12:44:45.590637Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"sorted_metrics_df.iloc[:2]","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:38:33.856120Z","iopub.execute_input":"2022-08-22T12:38:33.856579Z","iopub.status.idle":"2022-08-22T12:38:33.878735Z","shell.execute_reply.started":"2022-08-22T12:38:33.856517Z","shell.execute_reply":"2022-08-22T12:38:33.877445Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"- does 1-st model's train and validation intervals intersect each other?\n\nNo - that suggests that 1-st model is probably overfitted","metadata":{}},{"cell_type":"markdown","source":"- does 1-st and 2-nd model's train intervals intersect each other?\n\nNo","metadata":{}},{"cell_type":"markdown","source":"- does 1-st and 2-nd model's val intervals intersect each other? \n\nYes","metadata":{}},{"cell_type":"code","source":"from scipy.stats import ttest_rel","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:47:55.032282Z","iopub.execute_input":"2022-08-22T12:47:55.032701Z","iopub.status.idle":"2022-08-22T12:47:55.037821Z","shell.execute_reply.started":"2022-08-22T12:47:55.032658Z","shell.execute_reply":"2022-08-22T12:47:55.036645Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"first_model_train_mse = []\nfirst_model_val_mse = []\nsecond_model_train_mse = []\nsecond_model_val_mse = []\n\nfirst_model_val_preds = []\n\nfor k in tqdm(range(K)):\n    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, shuffle=True, random_state=k)\n    \n    first_model = lgbm.LGBMRegressor(n_estimators=1000, max_depth=3).fit(x_tr, y_tr)\n\n    preds_tr = first_model.predict(x_tr)\n    preds_val = first_model.predict(x_val)\n    \n    first_model_val_preds.append(preds_val)\n\n    first_model_train_mse.append(rmse(preds_tr, y_tr))\n    first_model_val_mse.append(rmse(preds_val, y_val))\n    \n    second_model = lgbm.LGBMRegressor(n_estimators=1000, max_depth=7).fit(x_tr, y_tr)\n\n    preds_tr = second_model.predict(x_tr)\n    preds_val = second_model.predict(x_val)\n\n    second_model_train_mse.append(rmse(preds_tr, y_tr))\n    second_model_val_mse.append(rmse(preds_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:00:41.965290Z","iopub.execute_input":"2022-08-22T13:00:41.966766Z","iopub.status.idle":"2022-08-22T13:00:56.814210Z","shell.execute_reply.started":"2022-08-22T13:00:41.966709Z","shell.execute_reply":"2022-08-22T13:00:56.813274Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"Student's test - test for mean difference\n\nExamples of uses cases:\n- test if model-1 avg(evaluation) quality equals to model-2 avg(evaluation) quality\n\nSo for alpha=0.05:\n- if p value obtained from student's test on test m1 vs test m2 is higher than 0.95, we can sat that their test performance is roughly the same\n- if p value obtained from student's test on test m1 vs test m2 is lower than 0.05, we can sat that their test performance is different\n- same applies to train","metadata":{}},{"cell_type":"code","source":"ttest_rel(first_model_train_mse, first_model_val_mse)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:49:02.431300Z","iopub.execute_input":"2022-08-22T12:49:02.431701Z","iopub.status.idle":"2022-08-22T12:49:02.441328Z","shell.execute_reply.started":"2022-08-22T12:49:02.431667Z","shell.execute_reply":"2022-08-22T12:49:02.440097Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"ttest_rel(first_model_train_mse, second_model_train_mse)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:49:08.442411Z","iopub.execute_input":"2022-08-22T12:49:08.442830Z","iopub.status.idle":"2022-08-22T12:49:08.451324Z","shell.execute_reply.started":"2022-08-22T12:49:08.442795Z","shell.execute_reply":"2022-08-22T12:49:08.450121Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"ttest_rel(first_model_val_mse, second_model_val_mse)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:49:10.899189Z","iopub.execute_input":"2022-08-22T12:49:10.899620Z","iopub.status.idle":"2022-08-22T12:49:10.906598Z","shell.execute_reply.started":"2022-08-22T12:49:10.899582Z","shell.execute_reply":"2022-08-22T12:49:10.905727Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"final_model = lgbm.LGBMRegressor(n_estimators=1000, max_depth=3).fit(x_train, y_train)\ny_pred = final_model.predict(x_test)\n\nsubmit = pd.DataFrame()\nsubmit['Id'] = test_data['Id']\nsubmit['SalePrice'] = np.exp(y_pred)\n\nsubmit","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:04:06.465529Z","iopub.execute_input":"2022-08-22T13:04:06.465963Z","iopub.status.idle":"2022-08-22T13:04:06.938689Z","shell.execute_reply.started":"2022-08-22T13:04:06.465928Z","shell.execute_reply":"2022-08-22T13:04:06.937507Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"submit.to_csv('/kaggle/working/lgb_estimators_1000_maxdepth_3.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:06:22.927789Z","iopub.execute_input":"2022-08-22T13:06:22.928680Z","iopub.status.idle":"2022-08-22T13:06:22.941439Z","shell.execute_reply.started":"2022-08-22T13:06:22.928628Z","shell.execute_reply":"2022-08-22T13:06:22.940512Z"},"trusted":true},"execution_count":44,"outputs":[]}]}