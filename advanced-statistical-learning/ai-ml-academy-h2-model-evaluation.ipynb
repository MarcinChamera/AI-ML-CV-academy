{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-08T11:03:11.619900Z","iopub.execute_input":"2022-09-08T11:03:11.621362Z","iopub.status.idle":"2022-09-08T11:03:11.647894Z","shell.execute_reply.started":"2022-09-08T11:03:11.621253Z","shell.execute_reply":"2022-09-08T11:03:11.647340Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\n/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\n/kaggle/input/house-prices-advanced-regression-techniques/train.csv\n/kaggle/input/house-prices-advanced-regression-techniques/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Homework description\n\n1. Take data from house pricing (kaggle)\n2. Prepare metrics. Using bootstrap fit K=10 models with different hyper parameters\n    - fit K linear regressions per several hyperparameters\n    - K gradient bostings per several hyperparameters\n    - K neural networks per several hyperparameters\n1. For each model and hyperparameter setup estimate confidence interval.\n2. Create a rate dashboard using avg metrics (train or validation avg metric). Take top-2 models and answer questions:\n    - do for 1-st model train and validation intervals intersect each other?\n    - do for 1-st and 2-nd model tr. intervals intersect each other?\n    - do for 1-st and 2-dn mode val. intervals intersect each other?\n1. Apply t-test to 1-st model (train-validation metrics). Apply same test for 1-st and 2-nd train metrics (for validation too)\n2. What model is the best? Does itâ€™s CI intersect other CI?\n","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-09-08T11:06:34.584514Z","iopub.execute_input":"2022-09-08T11:06:34.584870Z","iopub.status.idle":"2022-09-08T11:06:34.628914Z","shell.execute_reply.started":"2022-09-08T11:06:34.584842Z","shell.execute_reply":"2022-09-08T11:06:34.627910Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Features: simple, only floats and ints (data preprocessing was not part of this homework - and any other homework from this module of academy)","metadata":{}},{"cell_type":"code","source":"numeric_columns = [i for i, j in zip(train_data.columns, train_data.dtypes) if j in [np.int64, np.float64] and i not in ['SalePrice', 'Id']]\nx_train = train_data[numeric_columns].fillna(-1)\nx_test = test_data[numeric_columns].fillna(-1)","metadata":{"execution":{"iopub.status.busy":"2022-09-08T11:06:36.028723Z","iopub.execute_input":"2022-09-08T11:06:36.029048Z","iopub.status.idle":"2022-09-08T11:06:36.038326Z","shell.execute_reply.started":"2022-09-08T11:06:36.029024Z","shell.execute_reply":"2022-09-08T11:06:36.037495Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ny_train = np.log(train_data['SalePrice'])\n\n_ = plt.hist(y_train)","metadata":{"execution":{"iopub.status.busy":"2022-09-08T11:06:37.252526Z","iopub.execute_input":"2022-09-08T11:06:37.252907Z","iopub.status.idle":"2022-09-08T11:06:37.403612Z","shell.execute_reply.started":"2022-09-08T11:06:37.252873Z","shell.execute_reply":"2022-09-08T11:06:37.402663Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"Why target was logarithmized?\nBecause without logarithm, in test stage, for parametric models like linear regression or neural network, sale prices (target) will be smaller than 0","metadata":{}},{"cell_type":"code","source":"def rmse(a, b):\n    return ((a - b) ** 2).mean() ** 0.5","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:10:57.737357Z","iopub.execute_input":"2022-08-22T12:10:57.737745Z","iopub.status.idle":"2022-08-22T12:10:57.744836Z","shell.execute_reply.started":"2022-08-22T12:10:57.737711Z","shell.execute_reply":"2022-08-22T12:10:57.743688Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**Linear Regression (Elastic Net)**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import ElasticNet\nfrom tqdm import tqdm\n\nK = 10\n\npreds_train = []\npreds_validation = []\n\nlr_metrics = []\n\nhyperparameters = [\n    [1, 0.5],\n    [1, 1],\n    [1, 0],\n    [1, 0.25],\n    [1, 0.75],\n    [10, 0.5],\n    [10, 0.25],\n    [10, 0.75],\n    [10, 0],\n    [10, 1]\n]\n\nfor hyperparameters_i in tqdm(hyperparameters):\n    for k in range(K):\n        x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, shuffle=True, random_state=k)\n\n        lr = ElasticNet(alpha=hyperparameters_i[0], l1_ratio=hyperparameters_i[1]).fit(x_tr, y_tr)\n\n        preds_tr = lr.predict(x_tr)\n        preds_val = lr.predict(x_val)\n\n        preds_train.append(preds_tr)\n        preds_validation.append(preds_val)\n\n        train_mse = rmse(preds_tr, y_tr)\n        val_mse = rmse(preds_val, y_val)\n\n        lr_metrics.append({\n            'algorithm' : f'ElasticNet: alpha={hyperparameters_i[0]}, l1_ratio={hyperparameters_i[1]}',\n            'train_mse' : train_mse,\n            'val_mse' : val_mse,\n        })","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:10:57.746530Z","iopub.execute_input":"2022-08-22T12:10:57.747256Z","iopub.status.idle":"2022-08-22T12:11:04.700875Z","shell.execute_reply.started":"2022-08-22T12:10:57.747210Z","shell.execute_reply":"2022-08-22T12:11:04.699595Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":" 20%|â–ˆâ–ˆ        | 2/10 [00:00<00:03,  2.47it/s]/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+01, tolerance: 1.785e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.577e+01, tolerance: 1.712e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+01, tolerance: 1.728e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+01, tolerance: 1.823e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.610e+01, tolerance: 1.788e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.586e+01, tolerance: 1.729e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.526e+01, tolerance: 1.735e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.551e+01, tolerance: 1.726e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.474e+01, tolerance: 1.817e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.596e+01, tolerance: 1.743e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:04<00:00,  2.75it/s]/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.472e+01, tolerance: 1.785e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.800e+01, tolerance: 1.712e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+01, tolerance: 1.728e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.509e+01, tolerance: 1.823e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.827e+01, tolerance: 1.788e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.813e+01, tolerance: 1.729e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.740e+01, tolerance: 1.735e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.765e+01, tolerance: 1.726e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e+01, tolerance: 1.817e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.807e+01, tolerance: 1.743e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.77it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"lr_metrics_df = pd.DataFrame(lr_metrics)\nlr_metrics_df.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:11:04.706390Z","iopub.execute_input":"2022-08-22T12:11:04.708180Z","iopub.status.idle":"2022-08-22T12:11:04.747221Z","shell.execute_reply.started":"2022-08-22T12:11:04.708130Z","shell.execute_reply":"2022-08-22T12:11:04.745903Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                            algorithm  train_mse   val_mse\n0   ElasticNet: alpha=1, l1_ratio=0.5   0.169238  0.233481\n1   ElasticNet: alpha=1, l1_ratio=0.5   0.187198  0.169278\n2   ElasticNet: alpha=1, l1_ratio=0.5   0.156049  0.274354\n3   ElasticNet: alpha=1, l1_ratio=0.5   0.171529  0.233685\n4   ElasticNet: alpha=1, l1_ratio=0.5   0.187967  0.170356\n5   ElasticNet: alpha=1, l1_ratio=0.5   0.187491  0.166666\n6   ElasticNet: alpha=1, l1_ratio=0.5   0.183401  0.180795\n7   ElasticNet: alpha=1, l1_ratio=0.5   0.185447  0.174189\n8   ElasticNet: alpha=1, l1_ratio=0.5   0.182002  0.182845\n9   ElasticNet: alpha=1, l1_ratio=0.5   0.187622  0.169380\n10    ElasticNet: alpha=1, l1_ratio=1   0.177422  0.242136\n11    ElasticNet: alpha=1, l1_ratio=1   0.195436  0.176230\n12    ElasticNet: alpha=1, l1_ratio=1   0.164416  0.283534\n13    ElasticNet: alpha=1, l1_ratio=1   0.179229  0.244343\n14    ElasticNet: alpha=1, l1_ratio=1   0.195888  0.179453\n15    ElasticNet: alpha=1, l1_ratio=1   0.196323  0.170429\n16    ElasticNet: alpha=1, l1_ratio=1   0.191748  0.187458\n17    ElasticNet: alpha=1, l1_ratio=1   0.194935  0.181518\n18    ElasticNet: alpha=1, l1_ratio=1   0.190462  0.187834\n19    ElasticNet: alpha=1, l1_ratio=1   0.196053  0.178925","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>algorithm</th>\n      <th>train_mse</th>\n      <th>val_mse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ElasticNet: alpha=1, l1_ratio=0.5</td>\n      <td>0.169238</td>\n      <td>0.233481</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ElasticNet: alpha=1, l1_ratio=0.5</td>\n      <td>0.187198</td>\n      <td>0.169278</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ElasticNet: alpha=1, l1_ratio=0.5</td>\n      <td>0.156049</td>\n      <td>0.274354</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ElasticNet: alpha=1, l1_ratio=0.5</td>\n      <td>0.171529</td>\n      <td>0.233685</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ElasticNet: alpha=1, l1_ratio=0.5</td>\n      <td>0.187967</td>\n      <td>0.170356</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ElasticNet: alpha=1, l1_ratio=0.5</td>\n      <td>0.187491</td>\n      <td>0.166666</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ElasticNet: alpha=1, l1_ratio=0.5</td>\n      <td>0.183401</td>\n      <td>0.180795</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ElasticNet: alpha=1, l1_ratio=0.5</td>\n      <td>0.185447</td>\n      <td>0.174189</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ElasticNet: alpha=1, l1_ratio=0.5</td>\n      <td>0.182002</td>\n      <td>0.182845</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ElasticNet: alpha=1, l1_ratio=0.5</td>\n      <td>0.187622</td>\n      <td>0.169380</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ElasticNet: alpha=1, l1_ratio=1</td>\n      <td>0.177422</td>\n      <td>0.242136</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>ElasticNet: alpha=1, l1_ratio=1</td>\n      <td>0.195436</td>\n      <td>0.176230</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>ElasticNet: alpha=1, l1_ratio=1</td>\n      <td>0.164416</td>\n      <td>0.283534</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ElasticNet: alpha=1, l1_ratio=1</td>\n      <td>0.179229</td>\n      <td>0.244343</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>ElasticNet: alpha=1, l1_ratio=1</td>\n      <td>0.195888</td>\n      <td>0.179453</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>ElasticNet: alpha=1, l1_ratio=1</td>\n      <td>0.196323</td>\n      <td>0.170429</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>ElasticNet: alpha=1, l1_ratio=1</td>\n      <td>0.191748</td>\n      <td>0.187458</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>ElasticNet: alpha=1, l1_ratio=1</td>\n      <td>0.194935</td>\n      <td>0.181518</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ElasticNet: alpha=1, l1_ratio=1</td>\n      <td>0.190462</td>\n      <td>0.187834</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>ElasticNet: alpha=1, l1_ratio=1</td>\n      <td>0.196053</td>\n      <td>0.178925</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"grouped_lr_metrics_df = lr_metrics_df.groupby(['algorithm']).agg(['mean', 'std', 'count'])\ngrouped_lr_metrics_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:11:04.750291Z","iopub.execute_input":"2022-08-22T12:11:04.751768Z","iopub.status.idle":"2022-08-22T12:11:04.806457Z","shell.execute_reply.started":"2022-08-22T12:11:04.751718Z","shell.execute_reply":"2022-08-22T12:11:04.805266Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                   train_mse                   val_mse  \\\n                                        mean       std count      mean   \nalgorithm                                                                \nElasticNet: alpha=1, l1_ratio=0     0.155456  0.009898    10  0.172039   \nElasticNet: alpha=1, l1_ratio=0.25  0.176956  0.010732    10  0.193103   \nElasticNet: alpha=1, l1_ratio=0.5   0.179794  0.010727    10  0.195503   \nElasticNet: alpha=1, l1_ratio=0.75  0.183710  0.010807    10  0.199081   \nElasticNet: alpha=1, l1_ratio=1     0.188191  0.010875    10  0.203186   \n\n                                                    \n                                         std count  \nalgorithm                                           \nElasticNet: alpha=1, l1_ratio=0     0.036292    10  \nElasticNet: alpha=1, l1_ratio=0.25  0.036475    10  \nElasticNet: alpha=1, l1_ratio=0.5   0.037687    10  \nElasticNet: alpha=1, l1_ratio=0.75  0.038328    10  \nElasticNet: alpha=1, l1_ratio=1     0.038831    10  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">train_mse</th>\n      <th colspan=\"3\" halign=\"left\">val_mse</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>algorithm</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=0</th>\n      <td>0.155456</td>\n      <td>0.009898</td>\n      <td>10</td>\n      <td>0.172039</td>\n      <td>0.036292</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=0.25</th>\n      <td>0.176956</td>\n      <td>0.010732</td>\n      <td>10</td>\n      <td>0.193103</td>\n      <td>0.036475</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=0.5</th>\n      <td>0.179794</td>\n      <td>0.010727</td>\n      <td>10</td>\n      <td>0.195503</td>\n      <td>0.037687</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=0.75</th>\n      <td>0.183710</td>\n      <td>0.010807</td>\n      <td>10</td>\n      <td>0.199081</td>\n      <td>0.038328</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=1</th>\n      <td>0.188191</td>\n      <td>0.010875</td>\n      <td>10</td>\n      <td>0.203186</td>\n      <td>0.038831</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from scipy.stats import norm\na = 0.05\n# 95% confident interval\nxi = norm.ppf(1 - a / 2)\n\nlr_confidence_intervals_train = []\nlr_confidence_intervals_val = []\n\nfor i in range(len(hyperparameters)):\n    lr_confidence_intervals_train.append(\n        np.array([-1, 1]) * xi * grouped_lr_metrics_df.iloc[i]['train_mse']['std'] / grouped_lr_metrics_df.iloc[i]['train_mse']['count'] ** 0.5 + grouped_lr_metrics_df.iloc[i]['train_mse']['mean']\n    )\n\n    lr_confidence_intervals_val.append(\n        np.array([-1, 1]) * xi * grouped_lr_metrics_df.iloc[i]['val_mse']['std'] / grouped_lr_metrics_df.iloc[i]['val_mse']['count'] ** 0.5 + grouped_lr_metrics_df.iloc[i]['val_mse']['mean']\n    )","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:11:04.808464Z","iopub.execute_input":"2022-08-22T12:11:04.809306Z","iopub.status.idle":"2022-08-22T12:11:04.843083Z","shell.execute_reply.started":"2022-08-22T12:11:04.809259Z","shell.execute_reply":"2022-08-22T12:11:04.841678Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"lr_confidence_intervals_train","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:11:04.844482Z","iopub.execute_input":"2022-08-22T12:11:04.844974Z","iopub.status.idle":"2022-08-22T12:11:04.856482Z","shell.execute_reply.started":"2022-08-22T12:11:04.844939Z","shell.execute_reply":"2022-08-22T12:11:04.855334Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[array([0.1493212 , 0.16159058]),\n array([0.17030459, 0.18360807]),\n array([0.17314599, 0.18644273]),\n array([0.17701201, 0.19040881]),\n array([0.18145063, 0.19493172]),\n array([0.16494842, 0.17812757]),\n array([0.20638608, 0.21890269]),\n array([0.21622661, 0.23172625]),\n array([0.21842654, 0.23372508]),\n array([0.22086573, 0.23595126])]"},"metadata":{}}]},{"cell_type":"code","source":"lr_confidence_intervals_val","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:11:04.857890Z","iopub.execute_input":"2022-08-22T12:11:04.859110Z","iopub.status.idle":"2022-08-22T12:11:04.871595Z","shell.execute_reply.started":"2022-08-22T12:11:04.859072Z","shell.execute_reply":"2022-08-22T12:11:04.870511Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[array([0.14954598, 0.19453292]),\n array([0.17049553, 0.21570981]),\n array([0.17214484, 0.21886088]),\n array([0.17532625, 0.22283672]),\n array([0.1791184 , 0.22725343]),\n array([0.16655671, 0.21117228]),\n array([0.20317729, 0.2527156 ]),\n array([0.21631701, 0.26053072]),\n array([0.21869524, 0.26032711]),\n array([0.22146609, 0.26073999])]"},"metadata":{}}]},{"cell_type":"code","source":"grouped_lr_metrics_df['conf_inter_train_left'] = [lr_confidence_intervals_train_el[0] for lr_confidence_intervals_train_el in lr_confidence_intervals_train]\ngrouped_lr_metrics_df['conf_inter_train_right'] = [lr_confidence_intervals_train_el[1] for lr_confidence_intervals_train_el in lr_confidence_intervals_train]\ngrouped_lr_metrics_df['conf_inter_val_left'] = [lr_confidence_intervals_val_el[0] for lr_confidence_intervals_val_el in lr_confidence_intervals_val]\ngrouped_lr_metrics_df['conf_inter_val_right'] = [lr_confidence_intervals_val_el[1] for lr_confidence_intervals_val_el in lr_confidence_intervals_val]","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:11:04.872788Z","iopub.execute_input":"2022-08-22T12:11:04.873572Z","iopub.status.idle":"2022-08-22T12:11:04.890054Z","shell.execute_reply.started":"2022-08-22T12:11:04.873507Z","shell.execute_reply":"2022-08-22T12:11:04.888414Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Confidence intervals help to estimate quality of metrics and build statistical tests","metadata":{}},{"cell_type":"code","source":"grouped_lr_metrics_df","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:11:04.893856Z","iopub.execute_input":"2022-08-22T12:11:04.894194Z","iopub.status.idle":"2022-08-22T12:11:04.915853Z","shell.execute_reply.started":"2022-08-22T12:11:04.894162Z","shell.execute_reply":"2022-08-22T12:11:04.915026Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                    train_mse                   val_mse  \\\n                                         mean       std count      mean   \nalgorithm                                                                 \nElasticNet: alpha=1, l1_ratio=0      0.155456  0.009898    10  0.172039   \nElasticNet: alpha=1, l1_ratio=0.25   0.176956  0.010732    10  0.193103   \nElasticNet: alpha=1, l1_ratio=0.5    0.179794  0.010727    10  0.195503   \nElasticNet: alpha=1, l1_ratio=0.75   0.183710  0.010807    10  0.199081   \nElasticNet: alpha=1, l1_ratio=1      0.188191  0.010875    10  0.203186   \nElasticNet: alpha=10, l1_ratio=0     0.171538  0.010632    10  0.188864   \nElasticNet: alpha=10, l1_ratio=0.25  0.212644  0.010097    10  0.227946   \nElasticNet: alpha=10, l1_ratio=0.5   0.223976  0.012504    10  0.238424   \nElasticNet: alpha=10, l1_ratio=0.75  0.226076  0.012342    10  0.239511   \nElasticNet: alpha=10, l1_ratio=1     0.228408  0.012170    10  0.241103   \n\n                                                    conf_inter_train_left  \\\n                                          std count                         \nalgorithm                                                                   \nElasticNet: alpha=1, l1_ratio=0      0.036292    10              0.149321   \nElasticNet: alpha=1, l1_ratio=0.25   0.036475    10              0.170305   \nElasticNet: alpha=1, l1_ratio=0.5    0.037687    10              0.173146   \nElasticNet: alpha=1, l1_ratio=0.75   0.038328    10              0.177012   \nElasticNet: alpha=1, l1_ratio=1      0.038831    10              0.181451   \nElasticNet: alpha=10, l1_ratio=0     0.035992    10              0.164948   \nElasticNet: alpha=10, l1_ratio=0.25  0.039963    10              0.206386   \nElasticNet: alpha=10, l1_ratio=0.5   0.035668    10              0.216227   \nElasticNet: alpha=10, l1_ratio=0.75  0.033585    10              0.218427   \nElasticNet: alpha=10, l1_ratio=1     0.031683    10              0.220866   \n\n                                    conf_inter_train_right  \\\n                                                             \nalgorithm                                                    \nElasticNet: alpha=1, l1_ratio=0                   0.161591   \nElasticNet: alpha=1, l1_ratio=0.25                0.183608   \nElasticNet: alpha=1, l1_ratio=0.5                 0.186443   \nElasticNet: alpha=1, l1_ratio=0.75                0.190409   \nElasticNet: alpha=1, l1_ratio=1                   0.194932   \nElasticNet: alpha=10, l1_ratio=0                  0.178128   \nElasticNet: alpha=10, l1_ratio=0.25               0.218903   \nElasticNet: alpha=10, l1_ratio=0.5                0.231726   \nElasticNet: alpha=10, l1_ratio=0.75               0.233725   \nElasticNet: alpha=10, l1_ratio=1                  0.235951   \n\n                                    conf_inter_val_left conf_inter_val_right  \n                                                                              \nalgorithm                                                                     \nElasticNet: alpha=1, l1_ratio=0                0.149546             0.194533  \nElasticNet: alpha=1, l1_ratio=0.25             0.170496             0.215710  \nElasticNet: alpha=1, l1_ratio=0.5              0.172145             0.218861  \nElasticNet: alpha=1, l1_ratio=0.75             0.175326             0.222837  \nElasticNet: alpha=1, l1_ratio=1                0.179118             0.227253  \nElasticNet: alpha=10, l1_ratio=0               0.166557             0.211172  \nElasticNet: alpha=10, l1_ratio=0.25            0.203177             0.252716  \nElasticNet: alpha=10, l1_ratio=0.5             0.216317             0.260531  \nElasticNet: alpha=10, l1_ratio=0.75            0.218695             0.260327  \nElasticNet: alpha=10, l1_ratio=1               0.221466             0.260740  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">train_mse</th>\n      <th colspan=\"3\" halign=\"left\">val_mse</th>\n      <th>conf_inter_train_left</th>\n      <th>conf_inter_train_right</th>\n      <th>conf_inter_val_left</th>\n      <th>conf_inter_val_right</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n    <tr>\n      <th>algorithm</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=0</th>\n      <td>0.155456</td>\n      <td>0.009898</td>\n      <td>10</td>\n      <td>0.172039</td>\n      <td>0.036292</td>\n      <td>10</td>\n      <td>0.149321</td>\n      <td>0.161591</td>\n      <td>0.149546</td>\n      <td>0.194533</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=0.25</th>\n      <td>0.176956</td>\n      <td>0.010732</td>\n      <td>10</td>\n      <td>0.193103</td>\n      <td>0.036475</td>\n      <td>10</td>\n      <td>0.170305</td>\n      <td>0.183608</td>\n      <td>0.170496</td>\n      <td>0.215710</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=0.5</th>\n      <td>0.179794</td>\n      <td>0.010727</td>\n      <td>10</td>\n      <td>0.195503</td>\n      <td>0.037687</td>\n      <td>10</td>\n      <td>0.173146</td>\n      <td>0.186443</td>\n      <td>0.172145</td>\n      <td>0.218861</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=0.75</th>\n      <td>0.183710</td>\n      <td>0.010807</td>\n      <td>10</td>\n      <td>0.199081</td>\n      <td>0.038328</td>\n      <td>10</td>\n      <td>0.177012</td>\n      <td>0.190409</td>\n      <td>0.175326</td>\n      <td>0.222837</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=1</th>\n      <td>0.188191</td>\n      <td>0.010875</td>\n      <td>10</td>\n      <td>0.203186</td>\n      <td>0.038831</td>\n      <td>10</td>\n      <td>0.181451</td>\n      <td>0.194932</td>\n      <td>0.179118</td>\n      <td>0.227253</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=10, l1_ratio=0</th>\n      <td>0.171538</td>\n      <td>0.010632</td>\n      <td>10</td>\n      <td>0.188864</td>\n      <td>0.035992</td>\n      <td>10</td>\n      <td>0.164948</td>\n      <td>0.178128</td>\n      <td>0.166557</td>\n      <td>0.211172</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=10, l1_ratio=0.25</th>\n      <td>0.212644</td>\n      <td>0.010097</td>\n      <td>10</td>\n      <td>0.227946</td>\n      <td>0.039963</td>\n      <td>10</td>\n      <td>0.206386</td>\n      <td>0.218903</td>\n      <td>0.203177</td>\n      <td>0.252716</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=10, l1_ratio=0.5</th>\n      <td>0.223976</td>\n      <td>0.012504</td>\n      <td>10</td>\n      <td>0.238424</td>\n      <td>0.035668</td>\n      <td>10</td>\n      <td>0.216227</td>\n      <td>0.231726</td>\n      <td>0.216317</td>\n      <td>0.260531</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=10, l1_ratio=0.75</th>\n      <td>0.226076</td>\n      <td>0.012342</td>\n      <td>10</td>\n      <td>0.239511</td>\n      <td>0.033585</td>\n      <td>10</td>\n      <td>0.218427</td>\n      <td>0.233725</td>\n      <td>0.218695</td>\n      <td>0.260327</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=10, l1_ratio=1</th>\n      <td>0.228408</td>\n      <td>0.012170</td>\n      <td>10</td>\n      <td>0.241103</td>\n      <td>0.031683</td>\n      <td>10</td>\n      <td>0.220866</td>\n      <td>0.235951</td>\n      <td>0.221466</td>\n      <td>0.260740</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Gradient Boosting**","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgbm\n\npreds_train = []\npreds_validation = []\n\ngb_metrics = []\n\nhyperparameters = [\n    [1000, 3],\n    [2000, 3],\n    [1000, 4],\n    [2000, 4],\n    [1000, 5],\n    [2000, 5],\n    [1000, 6],\n    [2000, 6],\n    [1000, 7],\n    [2000, 7]\n]\n\nfor hyperparameters_i in tqdm(hyperparameters):\n    for k in range(K):\n        x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, shuffle=True, random_state=k)\n\n        lgbm_model = lgbm.LGBMRegressor(n_estimators=hyperparameters_i[0], max_depth=hyperparameters_i[1]).fit(x_tr, y_tr)\n\n        preds_tr = lgbm_model.predict(x_tr)\n        preds_val = lgbm_model.predict(x_val)\n\n        preds_train.append(preds_tr)\n        preds_validation.append(preds_val)\n\n        train_mse = rmse(preds_tr, y_tr)\n        val_mse = rmse(preds_val, y_val)\n\n        gb_metrics.append({\n            'algorithm' : f'LightGBM: n_estimators={hyperparameters_i[0]}, max_depth={hyperparameters_i[1]}',\n            'train_mse' : train_mse,\n            'val_mse' : val_mse,\n        })","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:11:04.917112Z","iopub.execute_input":"2022-08-22T12:11:04.917896Z","iopub.status.idle":"2022-08-22T12:13:00.637393Z","shell.execute_reply.started":"2022-08-22T12:11:04.917862Z","shell.execute_reply":"2022-08-22T12:13:00.636148Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:54<00:00, 11.48s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"gb_metrics_df = pd.DataFrame(gb_metrics)\ngb_metrics_df.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:13:00.639135Z","iopub.execute_input":"2022-08-22T12:13:00.639840Z","iopub.status.idle":"2022-08-22T12:13:00.655831Z","shell.execute_reply.started":"2022-08-22T12:13:00.639791Z","shell.execute_reply":"2022-08-22T12:13:00.654294Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                   algorithm  train_mse   val_mse\n0   LightGBM: n_estimators=1000, max_depth=3   0.039391  0.136037\n1   LightGBM: n_estimators=1000, max_depth=3   0.033377  0.134737\n2   LightGBM: n_estimators=1000, max_depth=3   0.034561  0.169602\n3   LightGBM: n_estimators=1000, max_depth=3   0.036088  0.137927\n4   LightGBM: n_estimators=1000, max_depth=3   0.035497  0.128505\n5   LightGBM: n_estimators=1000, max_depth=3   0.036529  0.136385\n6   LightGBM: n_estimators=1000, max_depth=3   0.035668  0.143858\n7   LightGBM: n_estimators=1000, max_depth=3   0.038170  0.139590\n8   LightGBM: n_estimators=1000, max_depth=3   0.036156  0.137390\n9   LightGBM: n_estimators=1000, max_depth=3   0.036360  0.131186\n10  LightGBM: n_estimators=2000, max_depth=3   0.018419  0.138390\n11  LightGBM: n_estimators=2000, max_depth=3   0.015024  0.137293\n12  LightGBM: n_estimators=2000, max_depth=3   0.015964  0.172668\n13  LightGBM: n_estimators=2000, max_depth=3   0.016966  0.139022\n14  LightGBM: n_estimators=2000, max_depth=3   0.016894  0.131485\n15  LightGBM: n_estimators=2000, max_depth=3   0.016822  0.139389\n16  LightGBM: n_estimators=2000, max_depth=3   0.016221  0.147615\n17  LightGBM: n_estimators=2000, max_depth=3   0.017754  0.141477\n18  LightGBM: n_estimators=2000, max_depth=3   0.018064  0.138042\n19  LightGBM: n_estimators=2000, max_depth=3   0.016899  0.134458","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>algorithm</th>\n      <th>train_mse</th>\n      <th>val_mse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LightGBM: n_estimators=1000, max_depth=3</td>\n      <td>0.039391</td>\n      <td>0.136037</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LightGBM: n_estimators=1000, max_depth=3</td>\n      <td>0.033377</td>\n      <td>0.134737</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LightGBM: n_estimators=1000, max_depth=3</td>\n      <td>0.034561</td>\n      <td>0.169602</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LightGBM: n_estimators=1000, max_depth=3</td>\n      <td>0.036088</td>\n      <td>0.137927</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LightGBM: n_estimators=1000, max_depth=3</td>\n      <td>0.035497</td>\n      <td>0.128505</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LightGBM: n_estimators=1000, max_depth=3</td>\n      <td>0.036529</td>\n      <td>0.136385</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LightGBM: n_estimators=1000, max_depth=3</td>\n      <td>0.035668</td>\n      <td>0.143858</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>LightGBM: n_estimators=1000, max_depth=3</td>\n      <td>0.038170</td>\n      <td>0.139590</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>LightGBM: n_estimators=1000, max_depth=3</td>\n      <td>0.036156</td>\n      <td>0.137390</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>LightGBM: n_estimators=1000, max_depth=3</td>\n      <td>0.036360</td>\n      <td>0.131186</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>LightGBM: n_estimators=2000, max_depth=3</td>\n      <td>0.018419</td>\n      <td>0.138390</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>LightGBM: n_estimators=2000, max_depth=3</td>\n      <td>0.015024</td>\n      <td>0.137293</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>LightGBM: n_estimators=2000, max_depth=3</td>\n      <td>0.015964</td>\n      <td>0.172668</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>LightGBM: n_estimators=2000, max_depth=3</td>\n      <td>0.016966</td>\n      <td>0.139022</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>LightGBM: n_estimators=2000, max_depth=3</td>\n      <td>0.016894</td>\n      <td>0.131485</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>LightGBM: n_estimators=2000, max_depth=3</td>\n      <td>0.016822</td>\n      <td>0.139389</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>LightGBM: n_estimators=2000, max_depth=3</td>\n      <td>0.016221</td>\n      <td>0.147615</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>LightGBM: n_estimators=2000, max_depth=3</td>\n      <td>0.017754</td>\n      <td>0.141477</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>LightGBM: n_estimators=2000, max_depth=3</td>\n      <td>0.018064</td>\n      <td>0.138042</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>LightGBM: n_estimators=2000, max_depth=3</td>\n      <td>0.016899</td>\n      <td>0.134458</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"grouped_gb_metrics_df = gb_metrics_df.groupby(['algorithm']).agg(['mean', 'std', 'count'])\ngrouped_gb_metrics_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:13:00.657284Z","iopub.execute_input":"2022-08-22T12:13:00.657660Z","iopub.status.idle":"2022-08-22T12:13:00.683807Z","shell.execute_reply.started":"2022-08-22T12:13:00.657625Z","shell.execute_reply":"2022-08-22T12:13:00.682833Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                         train_mse                   val_mse  \\\n                                              mean       std count      mean   \nalgorithm                                                                      \nLightGBM: n_estimators=1000, max_depth=3  0.036180  0.001688    10  0.139522   \nLightGBM: n_estimators=1000, max_depth=4  0.018597  0.001429    10  0.140509   \nLightGBM: n_estimators=1000, max_depth=5  0.009783  0.001431    10  0.141123   \nLightGBM: n_estimators=1000, max_depth=6  0.005681  0.001308    10  0.141097   \nLightGBM: n_estimators=1000, max_depth=7  0.004370  0.002027    10  0.140145   \n\n                                                          \n                                               std count  \nalgorithm                                                 \nLightGBM: n_estimators=1000, max_depth=3  0.011384    10  \nLightGBM: n_estimators=1000, max_depth=4  0.011021    10  \nLightGBM: n_estimators=1000, max_depth=5  0.010041    10  \nLightGBM: n_estimators=1000, max_depth=6  0.009484    10  \nLightGBM: n_estimators=1000, max_depth=7  0.010340    10  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">train_mse</th>\n      <th colspan=\"3\" halign=\"left\">val_mse</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>algorithm</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=3</th>\n      <td>0.036180</td>\n      <td>0.001688</td>\n      <td>10</td>\n      <td>0.139522</td>\n      <td>0.011384</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=4</th>\n      <td>0.018597</td>\n      <td>0.001429</td>\n      <td>10</td>\n      <td>0.140509</td>\n      <td>0.011021</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=5</th>\n      <td>0.009783</td>\n      <td>0.001431</td>\n      <td>10</td>\n      <td>0.141123</td>\n      <td>0.010041</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=6</th>\n      <td>0.005681</td>\n      <td>0.001308</td>\n      <td>10</td>\n      <td>0.141097</td>\n      <td>0.009484</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=7</th>\n      <td>0.004370</td>\n      <td>0.002027</td>\n      <td>10</td>\n      <td>0.140145</td>\n      <td>0.010340</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"gb_confidence_intervals_train = []\ngb_confidence_intervals_val = []\n\nfor i in range(len(hyperparameters)):\n    gb_confidence_intervals_train.append(\n        np.array([-1, 1]) * xi * grouped_gb_metrics_df.iloc[i]['train_mse']['std'] / grouped_gb_metrics_df.iloc[i]['train_mse']['count'] ** 0.5 + grouped_gb_metrics_df.iloc[i]['train_mse']['mean']\n    )\n\n    gb_confidence_intervals_val.append(\n        np.array([-1, 1]) * xi * grouped_gb_metrics_df.iloc[i]['val_mse']['std'] / grouped_gb_metrics_df.iloc[i]['val_mse']['count'] ** 0.5 + grouped_gb_metrics_df.iloc[i]['val_mse']['mean']\n    )","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:13:00.684837Z","iopub.execute_input":"2022-08-22T12:13:00.685259Z","iopub.status.idle":"2022-08-22T12:13:00.719773Z","shell.execute_reply.started":"2022-08-22T12:13:00.685219Z","shell.execute_reply":"2022-08-22T12:13:00.718409Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"grouped_gb_metrics_df['conf_inter_train_left'] = [gb_confidence_intervals_train_el[0] for gb_confidence_intervals_train_el in gb_confidence_intervals_train]\ngrouped_gb_metrics_df['conf_inter_train_right'] = [gb_confidence_intervals_train_el[1] for gb_confidence_intervals_train_el in gb_confidence_intervals_train]\ngrouped_gb_metrics_df['conf_inter_val_left'] = [gb_confidence_intervals_val_el[0] for gb_confidence_intervals_val_el in gb_confidence_intervals_val]\ngrouped_gb_metrics_df['conf_inter_val_right'] = [gb_confidence_intervals_val_el[1] for gb_confidence_intervals_val_el in gb_confidence_intervals_val]\n\ngrouped_gb_metrics_df","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:13:00.721263Z","iopub.execute_input":"2022-08-22T12:13:00.721681Z","iopub.status.idle":"2022-08-22T12:13:00.750936Z","shell.execute_reply.started":"2022-08-22T12:13:00.721644Z","shell.execute_reply":"2022-08-22T12:13:00.749629Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                         train_mse                   val_mse  \\\n                                              mean       std count      mean   \nalgorithm                                                                      \nLightGBM: n_estimators=1000, max_depth=3  0.036180  0.001688    10  0.139522   \nLightGBM: n_estimators=1000, max_depth=4  0.018597  0.001429    10  0.140509   \nLightGBM: n_estimators=1000, max_depth=5  0.009783  0.001431    10  0.141123   \nLightGBM: n_estimators=1000, max_depth=6  0.005681  0.001308    10  0.141097   \nLightGBM: n_estimators=1000, max_depth=7  0.004370  0.002027    10  0.140145   \nLightGBM: n_estimators=2000, max_depth=3  0.016903  0.001014    10  0.141984   \nLightGBM: n_estimators=2000, max_depth=4  0.005380  0.000593    10  0.141673   \nLightGBM: n_estimators=2000, max_depth=5  0.002046  0.000362    10  0.141750   \nLightGBM: n_estimators=2000, max_depth=6  0.001091  0.000376    10  0.141374   \nLightGBM: n_estimators=2000, max_depth=7  0.000886  0.000453    10  0.140296   \n\n                                                          \\\n                                               std count   \nalgorithm                                                  \nLightGBM: n_estimators=1000, max_depth=3  0.011384    10   \nLightGBM: n_estimators=1000, max_depth=4  0.011021    10   \nLightGBM: n_estimators=1000, max_depth=5  0.010041    10   \nLightGBM: n_estimators=1000, max_depth=6  0.009484    10   \nLightGBM: n_estimators=1000, max_depth=7  0.010340    10   \nLightGBM: n_estimators=2000, max_depth=3  0.011577    10   \nLightGBM: n_estimators=2000, max_depth=4  0.011088    10   \nLightGBM: n_estimators=2000, max_depth=5  0.010016    10   \nLightGBM: n_estimators=2000, max_depth=6  0.009421    10   \nLightGBM: n_estimators=2000, max_depth=7  0.010323    10   \n\n                                         conf_inter_train_left  \\\n                                                                 \nalgorithm                                                        \nLightGBM: n_estimators=1000, max_depth=3              0.035134   \nLightGBM: n_estimators=1000, max_depth=4              0.017712   \nLightGBM: n_estimators=1000, max_depth=5              0.008896   \nLightGBM: n_estimators=1000, max_depth=6              0.004871   \nLightGBM: n_estimators=1000, max_depth=7              0.003114   \nLightGBM: n_estimators=2000, max_depth=3              0.016274   \nLightGBM: n_estimators=2000, max_depth=4              0.005013   \nLightGBM: n_estimators=2000, max_depth=5              0.001822   \nLightGBM: n_estimators=2000, max_depth=6              0.000858   \nLightGBM: n_estimators=2000, max_depth=7              0.000605   \n\n                                         conf_inter_train_right  \\\n                                                                  \nalgorithm                                                         \nLightGBM: n_estimators=1000, max_depth=3               0.037226   \nLightGBM: n_estimators=1000, max_depth=4               0.019483   \nLightGBM: n_estimators=1000, max_depth=5               0.010670   \nLightGBM: n_estimators=1000, max_depth=6               0.006492   \nLightGBM: n_estimators=1000, max_depth=7               0.005627   \nLightGBM: n_estimators=2000, max_depth=3               0.017531   \nLightGBM: n_estimators=2000, max_depth=4               0.005748   \nLightGBM: n_estimators=2000, max_depth=5               0.002271   \nLightGBM: n_estimators=2000, max_depth=6               0.001325   \nLightGBM: n_estimators=2000, max_depth=7               0.001167   \n\n                                         conf_inter_val_left  \\\n                                                               \nalgorithm                                                      \nLightGBM: n_estimators=1000, max_depth=3            0.132466   \nLightGBM: n_estimators=1000, max_depth=4            0.133678   \nLightGBM: n_estimators=1000, max_depth=5            0.134900   \nLightGBM: n_estimators=1000, max_depth=6            0.135219   \nLightGBM: n_estimators=1000, max_depth=7            0.133737   \nLightGBM: n_estimators=2000, max_depth=3            0.134809   \nLightGBM: n_estimators=2000, max_depth=4            0.134801   \nLightGBM: n_estimators=2000, max_depth=5            0.135543   \nLightGBM: n_estimators=2000, max_depth=6            0.135535   \nLightGBM: n_estimators=2000, max_depth=7            0.133898   \n\n                                         conf_inter_val_right  \n                                                               \nalgorithm                                                      \nLightGBM: n_estimators=1000, max_depth=3             0.146578  \nLightGBM: n_estimators=1000, max_depth=4             0.147339  \nLightGBM: n_estimators=1000, max_depth=5             0.147346  \nLightGBM: n_estimators=1000, max_depth=6             0.146975  \nLightGBM: n_estimators=1000, max_depth=7             0.146554  \nLightGBM: n_estimators=2000, max_depth=3             0.149160  \nLightGBM: n_estimators=2000, max_depth=4             0.148546  \nLightGBM: n_estimators=2000, max_depth=5             0.147958  \nLightGBM: n_estimators=2000, max_depth=6             0.147213  \nLightGBM: n_estimators=2000, max_depth=7             0.146694  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">train_mse</th>\n      <th colspan=\"3\" halign=\"left\">val_mse</th>\n      <th>conf_inter_train_left</th>\n      <th>conf_inter_train_right</th>\n      <th>conf_inter_val_left</th>\n      <th>conf_inter_val_right</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n    <tr>\n      <th>algorithm</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=3</th>\n      <td>0.036180</td>\n      <td>0.001688</td>\n      <td>10</td>\n      <td>0.139522</td>\n      <td>0.011384</td>\n      <td>10</td>\n      <td>0.035134</td>\n      <td>0.037226</td>\n      <td>0.132466</td>\n      <td>0.146578</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=4</th>\n      <td>0.018597</td>\n      <td>0.001429</td>\n      <td>10</td>\n      <td>0.140509</td>\n      <td>0.011021</td>\n      <td>10</td>\n      <td>0.017712</td>\n      <td>0.019483</td>\n      <td>0.133678</td>\n      <td>0.147339</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=5</th>\n      <td>0.009783</td>\n      <td>0.001431</td>\n      <td>10</td>\n      <td>0.141123</td>\n      <td>0.010041</td>\n      <td>10</td>\n      <td>0.008896</td>\n      <td>0.010670</td>\n      <td>0.134900</td>\n      <td>0.147346</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=6</th>\n      <td>0.005681</td>\n      <td>0.001308</td>\n      <td>10</td>\n      <td>0.141097</td>\n      <td>0.009484</td>\n      <td>10</td>\n      <td>0.004871</td>\n      <td>0.006492</td>\n      <td>0.135219</td>\n      <td>0.146975</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=7</th>\n      <td>0.004370</td>\n      <td>0.002027</td>\n      <td>10</td>\n      <td>0.140145</td>\n      <td>0.010340</td>\n      <td>10</td>\n      <td>0.003114</td>\n      <td>0.005627</td>\n      <td>0.133737</td>\n      <td>0.146554</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=2000, max_depth=3</th>\n      <td>0.016903</td>\n      <td>0.001014</td>\n      <td>10</td>\n      <td>0.141984</td>\n      <td>0.011577</td>\n      <td>10</td>\n      <td>0.016274</td>\n      <td>0.017531</td>\n      <td>0.134809</td>\n      <td>0.149160</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=2000, max_depth=4</th>\n      <td>0.005380</td>\n      <td>0.000593</td>\n      <td>10</td>\n      <td>0.141673</td>\n      <td>0.011088</td>\n      <td>10</td>\n      <td>0.005013</td>\n      <td>0.005748</td>\n      <td>0.134801</td>\n      <td>0.148546</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=2000, max_depth=5</th>\n      <td>0.002046</td>\n      <td>0.000362</td>\n      <td>10</td>\n      <td>0.141750</td>\n      <td>0.010016</td>\n      <td>10</td>\n      <td>0.001822</td>\n      <td>0.002271</td>\n      <td>0.135543</td>\n      <td>0.147958</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=2000, max_depth=6</th>\n      <td>0.001091</td>\n      <td>0.000376</td>\n      <td>10</td>\n      <td>0.141374</td>\n      <td>0.009421</td>\n      <td>10</td>\n      <td>0.000858</td>\n      <td>0.001325</td>\n      <td>0.135535</td>\n      <td>0.147213</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=2000, max_depth=7</th>\n      <td>0.000886</td>\n      <td>0.000453</td>\n      <td>10</td>\n      <td>0.140296</td>\n      <td>0.010323</td>\n      <td>10</td>\n      <td>0.000605</td>\n      <td>0.001167</td>\n      <td>0.133898</td>\n      <td>0.146694</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Simple MLPRegressor, nothing more advanced like Keras, just to meet requirements - small amount of iterations & layers to don't spend too much time on training","metadata":{}},{"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\n\npreds_train = []\npreds_validation = []\n\nmlp_metrics = []\n\nMAX_ITER = 1000\n\nhyperparameters = [\n    (2000, 2000),\n    (2000, 2000, 2000),\n]\n\nfor hyperparameters_i in hyperparameters:\n    for k in tqdm(range(K)):\n        x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, shuffle=True, random_state=k)\n\n        mlp_model = MLPRegressor(hidden_layer_sizes=hyperparameters_i,max_iter=MAX_ITER).fit(x_tr, y_tr)\n    \n        preds_tr = mlp_model.predict(x_tr)\n        preds_val = mlp_model.predict(x_val)\n\n        preds_train.append(preds_tr)\n        preds_validation.append(preds_val)\n\n        train_mse = rmse(preds_tr, y_tr)\n        val_mse = rmse(preds_val, y_val)\n\n        mlp_metrics.append({\n            'algorithm' : f'MLPRegressor: hidden_layer_sizes={hyperparameters_i}, max_iter={MAX_ITER}',\n            'train_mse' : train_mse,\n            'val_mse' : val_mse,\n        })","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:13:00.752584Z","iopub.execute_input":"2022-08-22T12:13:00.753512Z","iopub.status.idle":"2022-08-22T12:38:33.681606Z","shell.execute_reply.started":"2022-08-22T12:13:00.753474Z","shell.execute_reply":"2022-08-22T12:38:33.680388Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [12:02<00:00, 72.29s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [13:29<00:00, 81.00s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"mlp_metrics_df = pd.DataFrame(mlp_metrics)\nmlp_metrics_df.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:38:33.683066Z","iopub.execute_input":"2022-08-22T12:38:33.688797Z","iopub.status.idle":"2022-08-22T12:38:33.712522Z","shell.execute_reply.started":"2022-08-22T12:38:33.688739Z","shell.execute_reply":"2022-08-22T12:38:33.711276Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                            algorithm   train_mse     val_mse\n0   MLPRegressor: hidden_layer_sizes=(2000, 2000),...   17.339947   17.324034\n1   MLPRegressor: hidden_layer_sizes=(2000, 2000),...    2.438191    2.319289\n2   MLPRegressor: hidden_layer_sizes=(2000, 2000),...    5.169659    5.370469\n3   MLPRegressor: hidden_layer_sizes=(2000, 2000),...    3.043064    3.735428\n4   MLPRegressor: hidden_layer_sizes=(2000, 2000),...    3.331672    2.343275\n5   MLPRegressor: hidden_layer_sizes=(2000, 2000),...    5.821462   11.458058\n6   MLPRegressor: hidden_layer_sizes=(2000, 2000),...    2.774894    4.197131\n7   MLPRegressor: hidden_layer_sizes=(2000, 2000),...    1.881359    6.031083\n8   MLPRegressor: hidden_layer_sizes=(2000, 2000),...    4.206540    5.140477\n9   MLPRegressor: hidden_layer_sizes=(2000, 2000),...    1.188573    1.519236\n10  MLPRegressor: hidden_layer_sizes=(2000, 2000, ...   13.298395   13.137158\n11  MLPRegressor: hidden_layer_sizes=(2000, 2000, ...   11.521629   10.813559\n12  MLPRegressor: hidden_layer_sizes=(2000, 2000, ...  235.466567  237.623424\n13  MLPRegressor: hidden_layer_sizes=(2000, 2000, ...   26.984379   30.413112\n14  MLPRegressor: hidden_layer_sizes=(2000, 2000, ...   55.370828   35.692625\n15  MLPRegressor: hidden_layer_sizes=(2000, 2000, ...   18.250182   16.064773\n16  MLPRegressor: hidden_layer_sizes=(2000, 2000, ...   14.404041   18.734289\n17  MLPRegressor: hidden_layer_sizes=(2000, 2000, ...    7.056329   11.799341\n18  MLPRegressor: hidden_layer_sizes=(2000, 2000, ...    2.393882    2.819127\n19  MLPRegressor: hidden_layer_sizes=(2000, 2000, ...   26.090485   41.702762","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>algorithm</th>\n      <th>train_mse</th>\n      <th>val_mse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000),...</td>\n      <td>17.339947</td>\n      <td>17.324034</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000),...</td>\n      <td>2.438191</td>\n      <td>2.319289</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000),...</td>\n      <td>5.169659</td>\n      <td>5.370469</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000),...</td>\n      <td>3.043064</td>\n      <td>3.735428</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000),...</td>\n      <td>3.331672</td>\n      <td>2.343275</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000),...</td>\n      <td>5.821462</td>\n      <td>11.458058</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000),...</td>\n      <td>2.774894</td>\n      <td>4.197131</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000),...</td>\n      <td>1.881359</td>\n      <td>6.031083</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000),...</td>\n      <td>4.206540</td>\n      <td>5.140477</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000),...</td>\n      <td>1.188573</td>\n      <td>1.519236</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000, ...</td>\n      <td>13.298395</td>\n      <td>13.137158</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000, ...</td>\n      <td>11.521629</td>\n      <td>10.813559</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000, ...</td>\n      <td>235.466567</td>\n      <td>237.623424</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000, ...</td>\n      <td>26.984379</td>\n      <td>30.413112</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000, ...</td>\n      <td>55.370828</td>\n      <td>35.692625</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000, ...</td>\n      <td>18.250182</td>\n      <td>16.064773</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000, ...</td>\n      <td>14.404041</td>\n      <td>18.734289</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000, ...</td>\n      <td>7.056329</td>\n      <td>11.799341</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000, ...</td>\n      <td>2.393882</td>\n      <td>2.819127</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>MLPRegressor: hidden_layer_sizes=(2000, 2000, ...</td>\n      <td>26.090485</td>\n      <td>41.702762</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"grouped_mlp_metrics_df = mlp_metrics_df.groupby(['algorithm']).agg(['mean', 'std', 'count'])\ngrouped_mlp_metrics_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:39:12.603432Z","iopub.execute_input":"2022-08-22T12:39:12.603993Z","iopub.status.idle":"2022-08-22T12:39:12.630881Z","shell.execute_reply.started":"2022-08-22T12:39:12.603944Z","shell.execute_reply":"2022-08-22T12:39:12.629710Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                                                    train_mse             \\\n                                                         mean        std   \nalgorithm                                                                  \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...   4.719536   4.657141   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...  41.083672  69.877898   \n\n                                                            val_mse  \\\n                                                   count       mean   \nalgorithm                                                             \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...    10   5.943848   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...    10  41.880017   \n\n                                                                     \n                                                          std count  \nalgorithm                                                            \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...   4.881983    10  \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...  69.848499    10  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">train_mse</th>\n      <th colspan=\"3\" halign=\"left\">val_mse</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>algorithm</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MLPRegressor: hidden_layer_sizes=(2000, 2000), max_iter=1000</th>\n      <td>4.719536</td>\n      <td>4.657141</td>\n      <td>10</td>\n      <td>5.943848</td>\n      <td>4.881983</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>MLPRegressor: hidden_layer_sizes=(2000, 2000, 2000), max_iter=1000</th>\n      <td>41.083672</td>\n      <td>69.877898</td>\n      <td>10</td>\n      <td>41.880017</td>\n      <td>69.848499</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"mlp_confidence_intervals_train = []\nmlp_confidence_intervals_val = []\n\nfor i in range(len(hyperparameters)):\n    mlp_confidence_intervals_train.append(\n        np.array([-1, 1]) * xi * grouped_mlp_metrics_df.iloc[i]['train_mse']['std'] / grouped_mlp_metrics_df.iloc[i]['train_mse']['count'] ** 0.5 + grouped_mlp_metrics_df.iloc[i]['train_mse']['mean']\n    )\n\n    mlp_confidence_intervals_val.append(\n        np.array([-1, 1]) * xi * grouped_mlp_metrics_df.iloc[i]['val_mse']['std'] / grouped_mlp_metrics_df.iloc[i]['val_mse']['count'] ** 0.5 + grouped_mlp_metrics_df.iloc[i]['val_mse']['mean']\n    )","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:39:17.478224Z","iopub.execute_input":"2022-08-22T12:39:17.478847Z","iopub.status.idle":"2022-08-22T12:39:17.492074Z","shell.execute_reply.started":"2022-08-22T12:39:17.478811Z","shell.execute_reply":"2022-08-22T12:39:17.490978Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"grouped_mlp_metrics_df['conf_inter_train_left'] = [mlp_confidence_intervals_train_el[0] for mlp_confidence_intervals_train_el in mlp_confidence_intervals_train]\ngrouped_mlp_metrics_df['conf_inter_train_right'] = [mlp_confidence_intervals_train_el[1] for mlp_confidence_intervals_train_el in mlp_confidence_intervals_train]\ngrouped_mlp_metrics_df['conf_inter_val_left'] = [mlp_confidence_intervals_val_el[0] for mlp_confidence_intervals_val_el in mlp_confidence_intervals_val]\ngrouped_mlp_metrics_df['conf_inter_val_right'] = [mlp_confidence_intervals_val_el[1] for mlp_confidence_intervals_val_el in mlp_confidence_intervals_val]\n\ngrouped_mlp_metrics_df","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:44:12.139910Z","iopub.execute_input":"2022-08-22T12:44:12.140329Z","iopub.status.idle":"2022-08-22T12:44:12.167130Z","shell.execute_reply.started":"2022-08-22T12:44:12.140294Z","shell.execute_reply":"2022-08-22T12:44:12.165912Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"                                                    train_mse             \\\n                                                         mean        std   \nalgorithm                                                                  \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...   4.719536   4.657141   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...  41.083672  69.877898   \n\n                                                            val_mse  \\\n                                                   count       mean   \nalgorithm                                                             \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...    10   5.943848   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...    10  41.880017   \n\n                                                                     \\\n                                                          std count   \nalgorithm                                                             \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...   4.881983    10   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...  69.848499    10   \n\n                                                   conf_inter_train_left  \\\n                                                                           \nalgorithm                                                                  \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...              1.833063   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...             -2.226302   \n\n                                                   conf_inter_train_right  \\\n                                                                            \nalgorithm                                                                   \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...               7.606009   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...              84.393646   \n\n                                                   conf_inter_val_left  \\\n                                                                         \nalgorithm                                                                \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...            2.918019   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...           -1.411735   \n\n                                                   conf_inter_val_right  \n                                                                         \nalgorithm                                                                \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...             8.969677  \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...            85.171769  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">train_mse</th>\n      <th colspan=\"3\" halign=\"left\">val_mse</th>\n      <th>conf_inter_train_left</th>\n      <th>conf_inter_train_right</th>\n      <th>conf_inter_val_left</th>\n      <th>conf_inter_val_right</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n    <tr>\n      <th>algorithm</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MLPRegressor: hidden_layer_sizes=(2000, 2000), max_iter=1000</th>\n      <td>4.719536</td>\n      <td>4.657141</td>\n      <td>10</td>\n      <td>5.943848</td>\n      <td>4.881983</td>\n      <td>10</td>\n      <td>1.833063</td>\n      <td>7.606009</td>\n      <td>2.918019</td>\n      <td>8.969677</td>\n    </tr>\n    <tr>\n      <th>MLPRegressor: hidden_layer_sizes=(2000, 2000, 2000), max_iter=1000</th>\n      <td>41.083672</td>\n      <td>69.877898</td>\n      <td>10</td>\n      <td>41.880017</td>\n      <td>69.848499</td>\n      <td>10</td>\n      <td>-2.226302</td>\n      <td>84.393646</td>\n      <td>-1.411735</td>\n      <td>85.171769</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"grouped_metrics_df = pd.concat([grouped_lr_metrics_df, grouped_gb_metrics_df, grouped_mlp_metrics_df], axis=0)\ngrouped_metrics_df","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:44:41.517032Z","iopub.execute_input":"2022-08-22T12:44:41.517458Z","iopub.status.idle":"2022-08-22T12:44:41.546389Z","shell.execute_reply.started":"2022-08-22T12:44:41.517422Z","shell.execute_reply":"2022-08-22T12:44:41.545252Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"                                                    train_mse             \\\n                                                         mean        std   \nalgorithm                                                                  \nElasticNet: alpha=1, l1_ratio=0                      0.155456   0.009898   \nElasticNet: alpha=1, l1_ratio=0.25                   0.176956   0.010732   \nElasticNet: alpha=1, l1_ratio=0.5                    0.179794   0.010727   \nElasticNet: alpha=1, l1_ratio=0.75                   0.183710   0.010807   \nElasticNet: alpha=1, l1_ratio=1                      0.188191   0.010875   \nElasticNet: alpha=10, l1_ratio=0                     0.171538   0.010632   \nElasticNet: alpha=10, l1_ratio=0.25                  0.212644   0.010097   \nElasticNet: alpha=10, l1_ratio=0.5                   0.223976   0.012504   \nElasticNet: alpha=10, l1_ratio=0.75                  0.226076   0.012342   \nElasticNet: alpha=10, l1_ratio=1                     0.228408   0.012170   \nLightGBM: n_estimators=1000, max_depth=3             0.036180   0.001688   \nLightGBM: n_estimators=1000, max_depth=4             0.018597   0.001429   \nLightGBM: n_estimators=1000, max_depth=5             0.009783   0.001431   \nLightGBM: n_estimators=1000, max_depth=6             0.005681   0.001308   \nLightGBM: n_estimators=1000, max_depth=7             0.004370   0.002027   \nLightGBM: n_estimators=2000, max_depth=3             0.016903   0.001014   \nLightGBM: n_estimators=2000, max_depth=4             0.005380   0.000593   \nLightGBM: n_estimators=2000, max_depth=5             0.002046   0.000362   \nLightGBM: n_estimators=2000, max_depth=6             0.001091   0.000376   \nLightGBM: n_estimators=2000, max_depth=7             0.000886   0.000453   \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...   4.719536   4.657141   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...  41.083672  69.877898   \n\n                                                            val_mse  \\\n                                                   count       mean   \nalgorithm                                                             \nElasticNet: alpha=1, l1_ratio=0                       10   0.172039   \nElasticNet: alpha=1, l1_ratio=0.25                    10   0.193103   \nElasticNet: alpha=1, l1_ratio=0.5                     10   0.195503   \nElasticNet: alpha=1, l1_ratio=0.75                    10   0.199081   \nElasticNet: alpha=1, l1_ratio=1                       10   0.203186   \nElasticNet: alpha=10, l1_ratio=0                      10   0.188864   \nElasticNet: alpha=10, l1_ratio=0.25                   10   0.227946   \nElasticNet: alpha=10, l1_ratio=0.5                    10   0.238424   \nElasticNet: alpha=10, l1_ratio=0.75                   10   0.239511   \nElasticNet: alpha=10, l1_ratio=1                      10   0.241103   \nLightGBM: n_estimators=1000, max_depth=3              10   0.139522   \nLightGBM: n_estimators=1000, max_depth=4              10   0.140509   \nLightGBM: n_estimators=1000, max_depth=5              10   0.141123   \nLightGBM: n_estimators=1000, max_depth=6              10   0.141097   \nLightGBM: n_estimators=1000, max_depth=7              10   0.140145   \nLightGBM: n_estimators=2000, max_depth=3              10   0.141984   \nLightGBM: n_estimators=2000, max_depth=4              10   0.141673   \nLightGBM: n_estimators=2000, max_depth=5              10   0.141750   \nLightGBM: n_estimators=2000, max_depth=6              10   0.141374   \nLightGBM: n_estimators=2000, max_depth=7              10   0.140296   \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...    10   5.943848   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...    10  41.880017   \n\n                                                                     \\\n                                                          std count   \nalgorithm                                                             \nElasticNet: alpha=1, l1_ratio=0                      0.036292    10   \nElasticNet: alpha=1, l1_ratio=0.25                   0.036475    10   \nElasticNet: alpha=1, l1_ratio=0.5                    0.037687    10   \nElasticNet: alpha=1, l1_ratio=0.75                   0.038328    10   \nElasticNet: alpha=1, l1_ratio=1                      0.038831    10   \nElasticNet: alpha=10, l1_ratio=0                     0.035992    10   \nElasticNet: alpha=10, l1_ratio=0.25                  0.039963    10   \nElasticNet: alpha=10, l1_ratio=0.5                   0.035668    10   \nElasticNet: alpha=10, l1_ratio=0.75                  0.033585    10   \nElasticNet: alpha=10, l1_ratio=1                     0.031683    10   \nLightGBM: n_estimators=1000, max_depth=3             0.011384    10   \nLightGBM: n_estimators=1000, max_depth=4             0.011021    10   \nLightGBM: n_estimators=1000, max_depth=5             0.010041    10   \nLightGBM: n_estimators=1000, max_depth=6             0.009484    10   \nLightGBM: n_estimators=1000, max_depth=7             0.010340    10   \nLightGBM: n_estimators=2000, max_depth=3             0.011577    10   \nLightGBM: n_estimators=2000, max_depth=4             0.011088    10   \nLightGBM: n_estimators=2000, max_depth=5             0.010016    10   \nLightGBM: n_estimators=2000, max_depth=6             0.009421    10   \nLightGBM: n_estimators=2000, max_depth=7             0.010323    10   \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...   4.881983    10   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...  69.848499    10   \n\n                                                   conf_inter_train_left  \\\n                                                                           \nalgorithm                                                                  \nElasticNet: alpha=1, l1_ratio=0                                 0.149321   \nElasticNet: alpha=1, l1_ratio=0.25                              0.170305   \nElasticNet: alpha=1, l1_ratio=0.5                               0.173146   \nElasticNet: alpha=1, l1_ratio=0.75                              0.177012   \nElasticNet: alpha=1, l1_ratio=1                                 0.181451   \nElasticNet: alpha=10, l1_ratio=0                                0.164948   \nElasticNet: alpha=10, l1_ratio=0.25                             0.206386   \nElasticNet: alpha=10, l1_ratio=0.5                              0.216227   \nElasticNet: alpha=10, l1_ratio=0.75                             0.218427   \nElasticNet: alpha=10, l1_ratio=1                                0.220866   \nLightGBM: n_estimators=1000, max_depth=3                        0.035134   \nLightGBM: n_estimators=1000, max_depth=4                        0.017712   \nLightGBM: n_estimators=1000, max_depth=5                        0.008896   \nLightGBM: n_estimators=1000, max_depth=6                        0.004871   \nLightGBM: n_estimators=1000, max_depth=7                        0.003114   \nLightGBM: n_estimators=2000, max_depth=3                        0.016274   \nLightGBM: n_estimators=2000, max_depth=4                        0.005013   \nLightGBM: n_estimators=2000, max_depth=5                        0.001822   \nLightGBM: n_estimators=2000, max_depth=6                        0.000858   \nLightGBM: n_estimators=2000, max_depth=7                        0.000605   \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...              1.833063   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...             -2.226302   \n\n                                                   conf_inter_train_right  \\\n                                                                            \nalgorithm                                                                   \nElasticNet: alpha=1, l1_ratio=0                                  0.161591   \nElasticNet: alpha=1, l1_ratio=0.25                               0.183608   \nElasticNet: alpha=1, l1_ratio=0.5                                0.186443   \nElasticNet: alpha=1, l1_ratio=0.75                               0.190409   \nElasticNet: alpha=1, l1_ratio=1                                  0.194932   \nElasticNet: alpha=10, l1_ratio=0                                 0.178128   \nElasticNet: alpha=10, l1_ratio=0.25                              0.218903   \nElasticNet: alpha=10, l1_ratio=0.5                               0.231726   \nElasticNet: alpha=10, l1_ratio=0.75                              0.233725   \nElasticNet: alpha=10, l1_ratio=1                                 0.235951   \nLightGBM: n_estimators=1000, max_depth=3                         0.037226   \nLightGBM: n_estimators=1000, max_depth=4                         0.019483   \nLightGBM: n_estimators=1000, max_depth=5                         0.010670   \nLightGBM: n_estimators=1000, max_depth=6                         0.006492   \nLightGBM: n_estimators=1000, max_depth=7                         0.005627   \nLightGBM: n_estimators=2000, max_depth=3                         0.017531   \nLightGBM: n_estimators=2000, max_depth=4                         0.005748   \nLightGBM: n_estimators=2000, max_depth=5                         0.002271   \nLightGBM: n_estimators=2000, max_depth=6                         0.001325   \nLightGBM: n_estimators=2000, max_depth=7                         0.001167   \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...               7.606009   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...              84.393646   \n\n                                                   conf_inter_val_left  \\\n                                                                         \nalgorithm                                                                \nElasticNet: alpha=1, l1_ratio=0                               0.149546   \nElasticNet: alpha=1, l1_ratio=0.25                            0.170496   \nElasticNet: alpha=1, l1_ratio=0.5                             0.172145   \nElasticNet: alpha=1, l1_ratio=0.75                            0.175326   \nElasticNet: alpha=1, l1_ratio=1                               0.179118   \nElasticNet: alpha=10, l1_ratio=0                              0.166557   \nElasticNet: alpha=10, l1_ratio=0.25                           0.203177   \nElasticNet: alpha=10, l1_ratio=0.5                            0.216317   \nElasticNet: alpha=10, l1_ratio=0.75                           0.218695   \nElasticNet: alpha=10, l1_ratio=1                              0.221466   \nLightGBM: n_estimators=1000, max_depth=3                      0.132466   \nLightGBM: n_estimators=1000, max_depth=4                      0.133678   \nLightGBM: n_estimators=1000, max_depth=5                      0.134900   \nLightGBM: n_estimators=1000, max_depth=6                      0.135219   \nLightGBM: n_estimators=1000, max_depth=7                      0.133737   \nLightGBM: n_estimators=2000, max_depth=3                      0.134809   \nLightGBM: n_estimators=2000, max_depth=4                      0.134801   \nLightGBM: n_estimators=2000, max_depth=5                      0.135543   \nLightGBM: n_estimators=2000, max_depth=6                      0.135535   \nLightGBM: n_estimators=2000, max_depth=7                      0.133898   \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...            2.918019   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...           -1.411735   \n\n                                                   conf_inter_val_right  \n                                                                         \nalgorithm                                                                \nElasticNet: alpha=1, l1_ratio=0                                0.194533  \nElasticNet: alpha=1, l1_ratio=0.25                             0.215710  \nElasticNet: alpha=1, l1_ratio=0.5                              0.218861  \nElasticNet: alpha=1, l1_ratio=0.75                             0.222837  \nElasticNet: alpha=1, l1_ratio=1                                0.227253  \nElasticNet: alpha=10, l1_ratio=0                               0.211172  \nElasticNet: alpha=10, l1_ratio=0.25                            0.252716  \nElasticNet: alpha=10, l1_ratio=0.5                             0.260531  \nElasticNet: alpha=10, l1_ratio=0.75                            0.260327  \nElasticNet: alpha=10, l1_ratio=1                               0.260740  \nLightGBM: n_estimators=1000, max_depth=3                       0.146578  \nLightGBM: n_estimators=1000, max_depth=4                       0.147339  \nLightGBM: n_estimators=1000, max_depth=5                       0.147346  \nLightGBM: n_estimators=1000, max_depth=6                       0.146975  \nLightGBM: n_estimators=1000, max_depth=7                       0.146554  \nLightGBM: n_estimators=2000, max_depth=3                       0.149160  \nLightGBM: n_estimators=2000, max_depth=4                       0.148546  \nLightGBM: n_estimators=2000, max_depth=5                       0.147958  \nLightGBM: n_estimators=2000, max_depth=6                       0.147213  \nLightGBM: n_estimators=2000, max_depth=7                       0.146694  \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...             8.969677  \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...            85.171769  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">train_mse</th>\n      <th colspan=\"3\" halign=\"left\">val_mse</th>\n      <th>conf_inter_train_left</th>\n      <th>conf_inter_train_right</th>\n      <th>conf_inter_val_left</th>\n      <th>conf_inter_val_right</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n    <tr>\n      <th>algorithm</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=0</th>\n      <td>0.155456</td>\n      <td>0.009898</td>\n      <td>10</td>\n      <td>0.172039</td>\n      <td>0.036292</td>\n      <td>10</td>\n      <td>0.149321</td>\n      <td>0.161591</td>\n      <td>0.149546</td>\n      <td>0.194533</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=0.25</th>\n      <td>0.176956</td>\n      <td>0.010732</td>\n      <td>10</td>\n      <td>0.193103</td>\n      <td>0.036475</td>\n      <td>10</td>\n      <td>0.170305</td>\n      <td>0.183608</td>\n      <td>0.170496</td>\n      <td>0.215710</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=0.5</th>\n      <td>0.179794</td>\n      <td>0.010727</td>\n      <td>10</td>\n      <td>0.195503</td>\n      <td>0.037687</td>\n      <td>10</td>\n      <td>0.173146</td>\n      <td>0.186443</td>\n      <td>0.172145</td>\n      <td>0.218861</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=0.75</th>\n      <td>0.183710</td>\n      <td>0.010807</td>\n      <td>10</td>\n      <td>0.199081</td>\n      <td>0.038328</td>\n      <td>10</td>\n      <td>0.177012</td>\n      <td>0.190409</td>\n      <td>0.175326</td>\n      <td>0.222837</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=1</th>\n      <td>0.188191</td>\n      <td>0.010875</td>\n      <td>10</td>\n      <td>0.203186</td>\n      <td>0.038831</td>\n      <td>10</td>\n      <td>0.181451</td>\n      <td>0.194932</td>\n      <td>0.179118</td>\n      <td>0.227253</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=10, l1_ratio=0</th>\n      <td>0.171538</td>\n      <td>0.010632</td>\n      <td>10</td>\n      <td>0.188864</td>\n      <td>0.035992</td>\n      <td>10</td>\n      <td>0.164948</td>\n      <td>0.178128</td>\n      <td>0.166557</td>\n      <td>0.211172</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=10, l1_ratio=0.25</th>\n      <td>0.212644</td>\n      <td>0.010097</td>\n      <td>10</td>\n      <td>0.227946</td>\n      <td>0.039963</td>\n      <td>10</td>\n      <td>0.206386</td>\n      <td>0.218903</td>\n      <td>0.203177</td>\n      <td>0.252716</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=10, l1_ratio=0.5</th>\n      <td>0.223976</td>\n      <td>0.012504</td>\n      <td>10</td>\n      <td>0.238424</td>\n      <td>0.035668</td>\n      <td>10</td>\n      <td>0.216227</td>\n      <td>0.231726</td>\n      <td>0.216317</td>\n      <td>0.260531</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=10, l1_ratio=0.75</th>\n      <td>0.226076</td>\n      <td>0.012342</td>\n      <td>10</td>\n      <td>0.239511</td>\n      <td>0.033585</td>\n      <td>10</td>\n      <td>0.218427</td>\n      <td>0.233725</td>\n      <td>0.218695</td>\n      <td>0.260327</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=10, l1_ratio=1</th>\n      <td>0.228408</td>\n      <td>0.012170</td>\n      <td>10</td>\n      <td>0.241103</td>\n      <td>0.031683</td>\n      <td>10</td>\n      <td>0.220866</td>\n      <td>0.235951</td>\n      <td>0.221466</td>\n      <td>0.260740</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=3</th>\n      <td>0.036180</td>\n      <td>0.001688</td>\n      <td>10</td>\n      <td>0.139522</td>\n      <td>0.011384</td>\n      <td>10</td>\n      <td>0.035134</td>\n      <td>0.037226</td>\n      <td>0.132466</td>\n      <td>0.146578</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=4</th>\n      <td>0.018597</td>\n      <td>0.001429</td>\n      <td>10</td>\n      <td>0.140509</td>\n      <td>0.011021</td>\n      <td>10</td>\n      <td>0.017712</td>\n      <td>0.019483</td>\n      <td>0.133678</td>\n      <td>0.147339</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=5</th>\n      <td>0.009783</td>\n      <td>0.001431</td>\n      <td>10</td>\n      <td>0.141123</td>\n      <td>0.010041</td>\n      <td>10</td>\n      <td>0.008896</td>\n      <td>0.010670</td>\n      <td>0.134900</td>\n      <td>0.147346</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=6</th>\n      <td>0.005681</td>\n      <td>0.001308</td>\n      <td>10</td>\n      <td>0.141097</td>\n      <td>0.009484</td>\n      <td>10</td>\n      <td>0.004871</td>\n      <td>0.006492</td>\n      <td>0.135219</td>\n      <td>0.146975</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=7</th>\n      <td>0.004370</td>\n      <td>0.002027</td>\n      <td>10</td>\n      <td>0.140145</td>\n      <td>0.010340</td>\n      <td>10</td>\n      <td>0.003114</td>\n      <td>0.005627</td>\n      <td>0.133737</td>\n      <td>0.146554</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=2000, max_depth=3</th>\n      <td>0.016903</td>\n      <td>0.001014</td>\n      <td>10</td>\n      <td>0.141984</td>\n      <td>0.011577</td>\n      <td>10</td>\n      <td>0.016274</td>\n      <td>0.017531</td>\n      <td>0.134809</td>\n      <td>0.149160</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=2000, max_depth=4</th>\n      <td>0.005380</td>\n      <td>0.000593</td>\n      <td>10</td>\n      <td>0.141673</td>\n      <td>0.011088</td>\n      <td>10</td>\n      <td>0.005013</td>\n      <td>0.005748</td>\n      <td>0.134801</td>\n      <td>0.148546</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=2000, max_depth=5</th>\n      <td>0.002046</td>\n      <td>0.000362</td>\n      <td>10</td>\n      <td>0.141750</td>\n      <td>0.010016</td>\n      <td>10</td>\n      <td>0.001822</td>\n      <td>0.002271</td>\n      <td>0.135543</td>\n      <td>0.147958</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=2000, max_depth=6</th>\n      <td>0.001091</td>\n      <td>0.000376</td>\n      <td>10</td>\n      <td>0.141374</td>\n      <td>0.009421</td>\n      <td>10</td>\n      <td>0.000858</td>\n      <td>0.001325</td>\n      <td>0.135535</td>\n      <td>0.147213</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=2000, max_depth=7</th>\n      <td>0.000886</td>\n      <td>0.000453</td>\n      <td>10</td>\n      <td>0.140296</td>\n      <td>0.010323</td>\n      <td>10</td>\n      <td>0.000605</td>\n      <td>0.001167</td>\n      <td>0.133898</td>\n      <td>0.146694</td>\n    </tr>\n    <tr>\n      <th>MLPRegressor: hidden_layer_sizes=(2000, 2000), max_iter=1000</th>\n      <td>4.719536</td>\n      <td>4.657141</td>\n      <td>10</td>\n      <td>5.943848</td>\n      <td>4.881983</td>\n      <td>10</td>\n      <td>1.833063</td>\n      <td>7.606009</td>\n      <td>2.918019</td>\n      <td>8.969677</td>\n    </tr>\n    <tr>\n      <th>MLPRegressor: hidden_layer_sizes=(2000, 2000, 2000), max_iter=1000</th>\n      <td>41.083672</td>\n      <td>69.877898</td>\n      <td>10</td>\n      <td>41.880017</td>\n      <td>69.848499</td>\n      <td>10</td>\n      <td>-2.226302</td>\n      <td>84.393646</td>\n      <td>-1.411735</td>\n      <td>85.171769</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sorted_metrics_df = grouped_metrics_df.sort_values(by=('val_mse', 'mean'))\nsorted_metrics_df","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:44:45.562456Z","iopub.execute_input":"2022-08-22T12:44:45.562868Z","iopub.status.idle":"2022-08-22T12:44:45.591818Z","shell.execute_reply.started":"2022-08-22T12:44:45.562833Z","shell.execute_reply":"2022-08-22T12:44:45.590637Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"                                                    train_mse             \\\n                                                         mean        std   \nalgorithm                                                                  \nLightGBM: n_estimators=1000, max_depth=3             0.036180   0.001688   \nLightGBM: n_estimators=1000, max_depth=7             0.004370   0.002027   \nLightGBM: n_estimators=2000, max_depth=7             0.000886   0.000453   \nLightGBM: n_estimators=1000, max_depth=4             0.018597   0.001429   \nLightGBM: n_estimators=1000, max_depth=6             0.005681   0.001308   \nLightGBM: n_estimators=1000, max_depth=5             0.009783   0.001431   \nLightGBM: n_estimators=2000, max_depth=6             0.001091   0.000376   \nLightGBM: n_estimators=2000, max_depth=4             0.005380   0.000593   \nLightGBM: n_estimators=2000, max_depth=5             0.002046   0.000362   \nLightGBM: n_estimators=2000, max_depth=3             0.016903   0.001014   \nElasticNet: alpha=1, l1_ratio=0                      0.155456   0.009898   \nElasticNet: alpha=10, l1_ratio=0                     0.171538   0.010632   \nElasticNet: alpha=1, l1_ratio=0.25                   0.176956   0.010732   \nElasticNet: alpha=1, l1_ratio=0.5                    0.179794   0.010727   \nElasticNet: alpha=1, l1_ratio=0.75                   0.183710   0.010807   \nElasticNet: alpha=1, l1_ratio=1                      0.188191   0.010875   \nElasticNet: alpha=10, l1_ratio=0.25                  0.212644   0.010097   \nElasticNet: alpha=10, l1_ratio=0.5                   0.223976   0.012504   \nElasticNet: alpha=10, l1_ratio=0.75                  0.226076   0.012342   \nElasticNet: alpha=10, l1_ratio=1                     0.228408   0.012170   \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...   4.719536   4.657141   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...  41.083672  69.877898   \n\n                                                            val_mse  \\\n                                                   count       mean   \nalgorithm                                                             \nLightGBM: n_estimators=1000, max_depth=3              10   0.139522   \nLightGBM: n_estimators=1000, max_depth=7              10   0.140145   \nLightGBM: n_estimators=2000, max_depth=7              10   0.140296   \nLightGBM: n_estimators=1000, max_depth=4              10   0.140509   \nLightGBM: n_estimators=1000, max_depth=6              10   0.141097   \nLightGBM: n_estimators=1000, max_depth=5              10   0.141123   \nLightGBM: n_estimators=2000, max_depth=6              10   0.141374   \nLightGBM: n_estimators=2000, max_depth=4              10   0.141673   \nLightGBM: n_estimators=2000, max_depth=5              10   0.141750   \nLightGBM: n_estimators=2000, max_depth=3              10   0.141984   \nElasticNet: alpha=1, l1_ratio=0                       10   0.172039   \nElasticNet: alpha=10, l1_ratio=0                      10   0.188864   \nElasticNet: alpha=1, l1_ratio=0.25                    10   0.193103   \nElasticNet: alpha=1, l1_ratio=0.5                     10   0.195503   \nElasticNet: alpha=1, l1_ratio=0.75                    10   0.199081   \nElasticNet: alpha=1, l1_ratio=1                       10   0.203186   \nElasticNet: alpha=10, l1_ratio=0.25                   10   0.227946   \nElasticNet: alpha=10, l1_ratio=0.5                    10   0.238424   \nElasticNet: alpha=10, l1_ratio=0.75                   10   0.239511   \nElasticNet: alpha=10, l1_ratio=1                      10   0.241103   \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...    10   5.943848   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...    10  41.880017   \n\n                                                                     \\\n                                                          std count   \nalgorithm                                                             \nLightGBM: n_estimators=1000, max_depth=3             0.011384    10   \nLightGBM: n_estimators=1000, max_depth=7             0.010340    10   \nLightGBM: n_estimators=2000, max_depth=7             0.010323    10   \nLightGBM: n_estimators=1000, max_depth=4             0.011021    10   \nLightGBM: n_estimators=1000, max_depth=6             0.009484    10   \nLightGBM: n_estimators=1000, max_depth=5             0.010041    10   \nLightGBM: n_estimators=2000, max_depth=6             0.009421    10   \nLightGBM: n_estimators=2000, max_depth=4             0.011088    10   \nLightGBM: n_estimators=2000, max_depth=5             0.010016    10   \nLightGBM: n_estimators=2000, max_depth=3             0.011577    10   \nElasticNet: alpha=1, l1_ratio=0                      0.036292    10   \nElasticNet: alpha=10, l1_ratio=0                     0.035992    10   \nElasticNet: alpha=1, l1_ratio=0.25                   0.036475    10   \nElasticNet: alpha=1, l1_ratio=0.5                    0.037687    10   \nElasticNet: alpha=1, l1_ratio=0.75                   0.038328    10   \nElasticNet: alpha=1, l1_ratio=1                      0.038831    10   \nElasticNet: alpha=10, l1_ratio=0.25                  0.039963    10   \nElasticNet: alpha=10, l1_ratio=0.5                   0.035668    10   \nElasticNet: alpha=10, l1_ratio=0.75                  0.033585    10   \nElasticNet: alpha=10, l1_ratio=1                     0.031683    10   \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...   4.881983    10   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...  69.848499    10   \n\n                                                   conf_inter_train_left  \\\n                                                                           \nalgorithm                                                                  \nLightGBM: n_estimators=1000, max_depth=3                        0.035134   \nLightGBM: n_estimators=1000, max_depth=7                        0.003114   \nLightGBM: n_estimators=2000, max_depth=7                        0.000605   \nLightGBM: n_estimators=1000, max_depth=4                        0.017712   \nLightGBM: n_estimators=1000, max_depth=6                        0.004871   \nLightGBM: n_estimators=1000, max_depth=5                        0.008896   \nLightGBM: n_estimators=2000, max_depth=6                        0.000858   \nLightGBM: n_estimators=2000, max_depth=4                        0.005013   \nLightGBM: n_estimators=2000, max_depth=5                        0.001822   \nLightGBM: n_estimators=2000, max_depth=3                        0.016274   \nElasticNet: alpha=1, l1_ratio=0                                 0.149321   \nElasticNet: alpha=10, l1_ratio=0                                0.164948   \nElasticNet: alpha=1, l1_ratio=0.25                              0.170305   \nElasticNet: alpha=1, l1_ratio=0.5                               0.173146   \nElasticNet: alpha=1, l1_ratio=0.75                              0.177012   \nElasticNet: alpha=1, l1_ratio=1                                 0.181451   \nElasticNet: alpha=10, l1_ratio=0.25                             0.206386   \nElasticNet: alpha=10, l1_ratio=0.5                              0.216227   \nElasticNet: alpha=10, l1_ratio=0.75                             0.218427   \nElasticNet: alpha=10, l1_ratio=1                                0.220866   \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...              1.833063   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...             -2.226302   \n\n                                                   conf_inter_train_right  \\\n                                                                            \nalgorithm                                                                   \nLightGBM: n_estimators=1000, max_depth=3                         0.037226   \nLightGBM: n_estimators=1000, max_depth=7                         0.005627   \nLightGBM: n_estimators=2000, max_depth=7                         0.001167   \nLightGBM: n_estimators=1000, max_depth=4                         0.019483   \nLightGBM: n_estimators=1000, max_depth=6                         0.006492   \nLightGBM: n_estimators=1000, max_depth=5                         0.010670   \nLightGBM: n_estimators=2000, max_depth=6                         0.001325   \nLightGBM: n_estimators=2000, max_depth=4                         0.005748   \nLightGBM: n_estimators=2000, max_depth=5                         0.002271   \nLightGBM: n_estimators=2000, max_depth=3                         0.017531   \nElasticNet: alpha=1, l1_ratio=0                                  0.161591   \nElasticNet: alpha=10, l1_ratio=0                                 0.178128   \nElasticNet: alpha=1, l1_ratio=0.25                               0.183608   \nElasticNet: alpha=1, l1_ratio=0.5                                0.186443   \nElasticNet: alpha=1, l1_ratio=0.75                               0.190409   \nElasticNet: alpha=1, l1_ratio=1                                  0.194932   \nElasticNet: alpha=10, l1_ratio=0.25                              0.218903   \nElasticNet: alpha=10, l1_ratio=0.5                               0.231726   \nElasticNet: alpha=10, l1_ratio=0.75                              0.233725   \nElasticNet: alpha=10, l1_ratio=1                                 0.235951   \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...               7.606009   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...              84.393646   \n\n                                                   conf_inter_val_left  \\\n                                                                         \nalgorithm                                                                \nLightGBM: n_estimators=1000, max_depth=3                      0.132466   \nLightGBM: n_estimators=1000, max_depth=7                      0.133737   \nLightGBM: n_estimators=2000, max_depth=7                      0.133898   \nLightGBM: n_estimators=1000, max_depth=4                      0.133678   \nLightGBM: n_estimators=1000, max_depth=6                      0.135219   \nLightGBM: n_estimators=1000, max_depth=5                      0.134900   \nLightGBM: n_estimators=2000, max_depth=6                      0.135535   \nLightGBM: n_estimators=2000, max_depth=4                      0.134801   \nLightGBM: n_estimators=2000, max_depth=5                      0.135543   \nLightGBM: n_estimators=2000, max_depth=3                      0.134809   \nElasticNet: alpha=1, l1_ratio=0                               0.149546   \nElasticNet: alpha=10, l1_ratio=0                              0.166557   \nElasticNet: alpha=1, l1_ratio=0.25                            0.170496   \nElasticNet: alpha=1, l1_ratio=0.5                             0.172145   \nElasticNet: alpha=1, l1_ratio=0.75                            0.175326   \nElasticNet: alpha=1, l1_ratio=1                               0.179118   \nElasticNet: alpha=10, l1_ratio=0.25                           0.203177   \nElasticNet: alpha=10, l1_ratio=0.5                            0.216317   \nElasticNet: alpha=10, l1_ratio=0.75                           0.218695   \nElasticNet: alpha=10, l1_ratio=1                              0.221466   \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...            2.918019   \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...           -1.411735   \n\n                                                   conf_inter_val_right  \n                                                                         \nalgorithm                                                                \nLightGBM: n_estimators=1000, max_depth=3                       0.146578  \nLightGBM: n_estimators=1000, max_depth=7                       0.146554  \nLightGBM: n_estimators=2000, max_depth=7                       0.146694  \nLightGBM: n_estimators=1000, max_depth=4                       0.147339  \nLightGBM: n_estimators=1000, max_depth=6                       0.146975  \nLightGBM: n_estimators=1000, max_depth=5                       0.147346  \nLightGBM: n_estimators=2000, max_depth=6                       0.147213  \nLightGBM: n_estimators=2000, max_depth=4                       0.148546  \nLightGBM: n_estimators=2000, max_depth=5                       0.147958  \nLightGBM: n_estimators=2000, max_depth=3                       0.149160  \nElasticNet: alpha=1, l1_ratio=0                                0.194533  \nElasticNet: alpha=10, l1_ratio=0                               0.211172  \nElasticNet: alpha=1, l1_ratio=0.25                             0.215710  \nElasticNet: alpha=1, l1_ratio=0.5                              0.218861  \nElasticNet: alpha=1, l1_ratio=0.75                             0.222837  \nElasticNet: alpha=1, l1_ratio=1                                0.227253  \nElasticNet: alpha=10, l1_ratio=0.25                            0.252716  \nElasticNet: alpha=10, l1_ratio=0.5                             0.260531  \nElasticNet: alpha=10, l1_ratio=0.75                            0.260327  \nElasticNet: alpha=10, l1_ratio=1                               0.260740  \nMLPRegressor: hidden_layer_sizes=(2000, 2000), ...             8.969677  \nMLPRegressor: hidden_layer_sizes=(2000, 2000, 2...            85.171769  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">train_mse</th>\n      <th colspan=\"3\" halign=\"left\">val_mse</th>\n      <th>conf_inter_train_left</th>\n      <th>conf_inter_train_right</th>\n      <th>conf_inter_val_left</th>\n      <th>conf_inter_val_right</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n    <tr>\n      <th>algorithm</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=3</th>\n      <td>0.036180</td>\n      <td>0.001688</td>\n      <td>10</td>\n      <td>0.139522</td>\n      <td>0.011384</td>\n      <td>10</td>\n      <td>0.035134</td>\n      <td>0.037226</td>\n      <td>0.132466</td>\n      <td>0.146578</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=7</th>\n      <td>0.004370</td>\n      <td>0.002027</td>\n      <td>10</td>\n      <td>0.140145</td>\n      <td>0.010340</td>\n      <td>10</td>\n      <td>0.003114</td>\n      <td>0.005627</td>\n      <td>0.133737</td>\n      <td>0.146554</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=2000, max_depth=7</th>\n      <td>0.000886</td>\n      <td>0.000453</td>\n      <td>10</td>\n      <td>0.140296</td>\n      <td>0.010323</td>\n      <td>10</td>\n      <td>0.000605</td>\n      <td>0.001167</td>\n      <td>0.133898</td>\n      <td>0.146694</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=4</th>\n      <td>0.018597</td>\n      <td>0.001429</td>\n      <td>10</td>\n      <td>0.140509</td>\n      <td>0.011021</td>\n      <td>10</td>\n      <td>0.017712</td>\n      <td>0.019483</td>\n      <td>0.133678</td>\n      <td>0.147339</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=6</th>\n      <td>0.005681</td>\n      <td>0.001308</td>\n      <td>10</td>\n      <td>0.141097</td>\n      <td>0.009484</td>\n      <td>10</td>\n      <td>0.004871</td>\n      <td>0.006492</td>\n      <td>0.135219</td>\n      <td>0.146975</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=5</th>\n      <td>0.009783</td>\n      <td>0.001431</td>\n      <td>10</td>\n      <td>0.141123</td>\n      <td>0.010041</td>\n      <td>10</td>\n      <td>0.008896</td>\n      <td>0.010670</td>\n      <td>0.134900</td>\n      <td>0.147346</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=2000, max_depth=6</th>\n      <td>0.001091</td>\n      <td>0.000376</td>\n      <td>10</td>\n      <td>0.141374</td>\n      <td>0.009421</td>\n      <td>10</td>\n      <td>0.000858</td>\n      <td>0.001325</td>\n      <td>0.135535</td>\n      <td>0.147213</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=2000, max_depth=4</th>\n      <td>0.005380</td>\n      <td>0.000593</td>\n      <td>10</td>\n      <td>0.141673</td>\n      <td>0.011088</td>\n      <td>10</td>\n      <td>0.005013</td>\n      <td>0.005748</td>\n      <td>0.134801</td>\n      <td>0.148546</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=2000, max_depth=5</th>\n      <td>0.002046</td>\n      <td>0.000362</td>\n      <td>10</td>\n      <td>0.141750</td>\n      <td>0.010016</td>\n      <td>10</td>\n      <td>0.001822</td>\n      <td>0.002271</td>\n      <td>0.135543</td>\n      <td>0.147958</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=2000, max_depth=3</th>\n      <td>0.016903</td>\n      <td>0.001014</td>\n      <td>10</td>\n      <td>0.141984</td>\n      <td>0.011577</td>\n      <td>10</td>\n      <td>0.016274</td>\n      <td>0.017531</td>\n      <td>0.134809</td>\n      <td>0.149160</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=0</th>\n      <td>0.155456</td>\n      <td>0.009898</td>\n      <td>10</td>\n      <td>0.172039</td>\n      <td>0.036292</td>\n      <td>10</td>\n      <td>0.149321</td>\n      <td>0.161591</td>\n      <td>0.149546</td>\n      <td>0.194533</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=10, l1_ratio=0</th>\n      <td>0.171538</td>\n      <td>0.010632</td>\n      <td>10</td>\n      <td>0.188864</td>\n      <td>0.035992</td>\n      <td>10</td>\n      <td>0.164948</td>\n      <td>0.178128</td>\n      <td>0.166557</td>\n      <td>0.211172</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=0.25</th>\n      <td>0.176956</td>\n      <td>0.010732</td>\n      <td>10</td>\n      <td>0.193103</td>\n      <td>0.036475</td>\n      <td>10</td>\n      <td>0.170305</td>\n      <td>0.183608</td>\n      <td>0.170496</td>\n      <td>0.215710</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=0.5</th>\n      <td>0.179794</td>\n      <td>0.010727</td>\n      <td>10</td>\n      <td>0.195503</td>\n      <td>0.037687</td>\n      <td>10</td>\n      <td>0.173146</td>\n      <td>0.186443</td>\n      <td>0.172145</td>\n      <td>0.218861</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=0.75</th>\n      <td>0.183710</td>\n      <td>0.010807</td>\n      <td>10</td>\n      <td>0.199081</td>\n      <td>0.038328</td>\n      <td>10</td>\n      <td>0.177012</td>\n      <td>0.190409</td>\n      <td>0.175326</td>\n      <td>0.222837</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=1, l1_ratio=1</th>\n      <td>0.188191</td>\n      <td>0.010875</td>\n      <td>10</td>\n      <td>0.203186</td>\n      <td>0.038831</td>\n      <td>10</td>\n      <td>0.181451</td>\n      <td>0.194932</td>\n      <td>0.179118</td>\n      <td>0.227253</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=10, l1_ratio=0.25</th>\n      <td>0.212644</td>\n      <td>0.010097</td>\n      <td>10</td>\n      <td>0.227946</td>\n      <td>0.039963</td>\n      <td>10</td>\n      <td>0.206386</td>\n      <td>0.218903</td>\n      <td>0.203177</td>\n      <td>0.252716</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=10, l1_ratio=0.5</th>\n      <td>0.223976</td>\n      <td>0.012504</td>\n      <td>10</td>\n      <td>0.238424</td>\n      <td>0.035668</td>\n      <td>10</td>\n      <td>0.216227</td>\n      <td>0.231726</td>\n      <td>0.216317</td>\n      <td>0.260531</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=10, l1_ratio=0.75</th>\n      <td>0.226076</td>\n      <td>0.012342</td>\n      <td>10</td>\n      <td>0.239511</td>\n      <td>0.033585</td>\n      <td>10</td>\n      <td>0.218427</td>\n      <td>0.233725</td>\n      <td>0.218695</td>\n      <td>0.260327</td>\n    </tr>\n    <tr>\n      <th>ElasticNet: alpha=10, l1_ratio=1</th>\n      <td>0.228408</td>\n      <td>0.012170</td>\n      <td>10</td>\n      <td>0.241103</td>\n      <td>0.031683</td>\n      <td>10</td>\n      <td>0.220866</td>\n      <td>0.235951</td>\n      <td>0.221466</td>\n      <td>0.260740</td>\n    </tr>\n    <tr>\n      <th>MLPRegressor: hidden_layer_sizes=(2000, 2000), max_iter=1000</th>\n      <td>4.719536</td>\n      <td>4.657141</td>\n      <td>10</td>\n      <td>5.943848</td>\n      <td>4.881983</td>\n      <td>10</td>\n      <td>1.833063</td>\n      <td>7.606009</td>\n      <td>2.918019</td>\n      <td>8.969677</td>\n    </tr>\n    <tr>\n      <th>MLPRegressor: hidden_layer_sizes=(2000, 2000, 2000), max_iter=1000</th>\n      <td>41.083672</td>\n      <td>69.877898</td>\n      <td>10</td>\n      <td>41.880017</td>\n      <td>69.848499</td>\n      <td>10</td>\n      <td>-2.226302</td>\n      <td>84.393646</td>\n      <td>-1.411735</td>\n      <td>85.171769</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sorted_metrics_df.iloc[:2]","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:38:33.856120Z","iopub.execute_input":"2022-08-22T12:38:33.856579Z","iopub.status.idle":"2022-08-22T12:38:33.878735Z","shell.execute_reply.started":"2022-08-22T12:38:33.856517Z","shell.execute_reply":"2022-08-22T12:38:33.877445Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                         train_mse                   val_mse  \\\n                                              mean       std count      mean   \nalgorithm                                                                      \nLightGBM: n_estimators=1000, max_depth=3   0.03618  0.001688    10  0.139522   \nLightGBM: n_estimators=1000, max_depth=7   0.00437  0.002027    10  0.140145   \n\n                                                          \\\n                                               std count   \nalgorithm                                                  \nLightGBM: n_estimators=1000, max_depth=3  0.011384    10   \nLightGBM: n_estimators=1000, max_depth=7  0.010340    10   \n\n                                         conf_inter_train_left  \\\n                                                                 \nalgorithm                                                        \nLightGBM: n_estimators=1000, max_depth=3              0.035134   \nLightGBM: n_estimators=1000, max_depth=7              0.003114   \n\n                                         conf_inter_train_right  \\\n                                                                  \nalgorithm                                                         \nLightGBM: n_estimators=1000, max_depth=3               0.037226   \nLightGBM: n_estimators=1000, max_depth=7               0.005627   \n\n                                         conf_inter_val_left  \\\n                                                               \nalgorithm                                                      \nLightGBM: n_estimators=1000, max_depth=3            0.132466   \nLightGBM: n_estimators=1000, max_depth=7            0.133737   \n\n                                         conf_inter_val_right  \n                                                               \nalgorithm                                                      \nLightGBM: n_estimators=1000, max_depth=3             0.146578  \nLightGBM: n_estimators=1000, max_depth=7             0.146554  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">train_mse</th>\n      <th colspan=\"3\" halign=\"left\">val_mse</th>\n      <th>conf_inter_train_left</th>\n      <th>conf_inter_train_right</th>\n      <th>conf_inter_val_left</th>\n      <th>conf_inter_val_right</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n    <tr>\n      <th>algorithm</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=3</th>\n      <td>0.03618</td>\n      <td>0.001688</td>\n      <td>10</td>\n      <td>0.139522</td>\n      <td>0.011384</td>\n      <td>10</td>\n      <td>0.035134</td>\n      <td>0.037226</td>\n      <td>0.132466</td>\n      <td>0.146578</td>\n    </tr>\n    <tr>\n      <th>LightGBM: n_estimators=1000, max_depth=7</th>\n      <td>0.00437</td>\n      <td>0.002027</td>\n      <td>10</td>\n      <td>0.140145</td>\n      <td>0.010340</td>\n      <td>10</td>\n      <td>0.003114</td>\n      <td>0.005627</td>\n      <td>0.133737</td>\n      <td>0.146554</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"- does 1-st model's train and validation intervals intersect each other?\n\nNo - that suggests that 1-st model is probably overfitted","metadata":{}},{"cell_type":"markdown","source":"- does 1-st and 2-nd model's train intervals intersect each other?\n\nNo","metadata":{}},{"cell_type":"markdown","source":"- does 1-st and 2-nd model's val intervals intersect each other? \n\nYes","metadata":{}},{"cell_type":"code","source":"from scipy.stats import ttest_rel","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:47:55.032282Z","iopub.execute_input":"2022-08-22T12:47:55.032701Z","iopub.status.idle":"2022-08-22T12:47:55.037821Z","shell.execute_reply.started":"2022-08-22T12:47:55.032658Z","shell.execute_reply":"2022-08-22T12:47:55.036645Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"first_model_train_mse = []\nfirst_model_val_mse = []\nsecond_model_train_mse = []\nsecond_model_val_mse = []\n\nfirst_model_val_preds = []\n\nfor k in tqdm(range(K)):\n    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, shuffle=True, random_state=k)\n    \n    first_model = lgbm.LGBMRegressor(n_estimators=1000, max_depth=3).fit(x_tr, y_tr)\n\n    preds_tr = first_model.predict(x_tr)\n    preds_val = first_model.predict(x_val)\n    \n    first_model_val_preds.append(preds_val)\n\n    first_model_train_mse.append(rmse(preds_tr, y_tr))\n    first_model_val_mse.append(rmse(preds_val, y_val))\n    \n    second_model = lgbm.LGBMRegressor(n_estimators=1000, max_depth=7).fit(x_tr, y_tr)\n\n    preds_tr = second_model.predict(x_tr)\n    preds_val = second_model.predict(x_val)\n\n    second_model_train_mse.append(rmse(preds_tr, y_tr))\n    second_model_val_mse.append(rmse(preds_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:00:41.965290Z","iopub.execute_input":"2022-08-22T13:00:41.966766Z","iopub.status.idle":"2022-08-22T13:00:56.814210Z","shell.execute_reply.started":"2022-08-22T13:00:41.966709Z","shell.execute_reply":"2022-08-22T13:00:56.813274Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:14<00:00,  1.48s/it]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Student's test - test for mean difference\n\nExamples of uses cases:\n- test if model-1 avg(evaluation) quality equals to model-2 avg(evaluation) quality\n\nSo for alpha=0.05:\n- if p value obtained from student's test on test m1 vs test m2 is higher than 0.95, we can sat that their test performance is roughly the same\n- if p value obtained from student's test on test m1 vs test m2 is lower than 0.05, we can sat that their test performance is different\n- same applies to train","metadata":{}},{"cell_type":"code","source":"ttest_rel(first_model_train_mse, first_model_val_mse)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:49:02.431300Z","iopub.execute_input":"2022-08-22T12:49:02.431701Z","iopub.status.idle":"2022-08-22T12:49:02.441328Z","shell.execute_reply.started":"2022-08-22T12:49:02.431667Z","shell.execute_reply":"2022-08-22T12:49:02.440097Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"Ttest_relResult(statistic=-27.41405820152407, pvalue=5.545733482249465e-10)"},"metadata":{}}]},{"cell_type":"code","source":"ttest_rel(first_model_train_mse, second_model_train_mse)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:49:08.442411Z","iopub.execute_input":"2022-08-22T12:49:08.442830Z","iopub.status.idle":"2022-08-22T12:49:08.451324Z","shell.execute_reply.started":"2022-08-22T12:49:08.442795Z","shell.execute_reply":"2022-08-22T12:49:08.450121Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"Ttest_relResult(statistic=53.43784631774485, pvalue=1.4146190437322727e-12)"},"metadata":{}}]},{"cell_type":"code","source":"ttest_rel(first_model_val_mse, second_model_val_mse)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T12:49:10.899189Z","iopub.execute_input":"2022-08-22T12:49:10.899620Z","iopub.status.idle":"2022-08-22T12:49:10.906598Z","shell.execute_reply.started":"2022-08-22T12:49:10.899582Z","shell.execute_reply":"2022-08-22T12:49:10.905727Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"Ttest_relResult(statistic=-0.5811966836001277, pvalue=0.57537206807982)"},"metadata":{}}]},{"cell_type":"code","source":"final_model = lgbm.LGBMRegressor(n_estimators=1000, max_depth=3).fit(x_train, y_train)\ny_pred = final_model.predict(x_test)\n\nsubmit = pd.DataFrame()\nsubmit['Id'] = test_data['Id']\nsubmit['SalePrice'] = np.exp(y_pred)\n\nsubmit","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:04:06.465529Z","iopub.execute_input":"2022-08-22T13:04:06.465963Z","iopub.status.idle":"2022-08-22T13:04:06.938689Z","shell.execute_reply.started":"2022-08-22T13:04:06.465928Z","shell.execute_reply":"2022-08-22T13:04:06.937507Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"        Id      SalePrice\n0     1461  121380.394034\n1     1462  156596.572334\n2     1463  189708.822182\n3     1464  192597.664984\n4     1465  180056.844779\n...    ...            ...\n1454  2915   71475.411742\n1455  2916   86382.208194\n1456  2917  182003.519476\n1457  2918  110318.229251\n1458  2919  233082.446085\n\n[1459 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1461</td>\n      <td>121380.394034</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1462</td>\n      <td>156596.572334</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1463</td>\n      <td>189708.822182</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1464</td>\n      <td>192597.664984</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1465</td>\n      <td>180056.844779</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1454</th>\n      <td>2915</td>\n      <td>71475.411742</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>2916</td>\n      <td>86382.208194</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>2917</td>\n      <td>182003.519476</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>2918</td>\n      <td>110318.229251</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>2919</td>\n      <td>233082.446085</td>\n    </tr>\n  </tbody>\n</table>\n<p>1459 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submit.to_csv('/kaggle/working/lgb_estimators_1000_maxdepth_3.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T13:06:22.927789Z","iopub.execute_input":"2022-08-22T13:06:22.928680Z","iopub.status.idle":"2022-08-22T13:06:22.941439Z","shell.execute_reply.started":"2022-08-22T13:06:22.928628Z","shell.execute_reply":"2022-08-22T13:06:22.940512Z"},"trusted":true},"execution_count":44,"outputs":[]}]}