{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-28T16:35:53.077094Z","iopub.execute_input":"2022-08-28T16:35:53.077371Z","iopub.status.idle":"2022-08-28T16:35:53.084795Z","shell.execute_reply.started":"2022-08-28T16:35:53.077345Z","shell.execute_reply":"2022-08-28T16:35:53.083787Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Homework description\n\n1. Take data from house pricing (kaggle)\n2. Try different GB libraries for regression:\n- sklearn, 10 models ensemble\n- lightgbm, 10 models ensemble\n- xgboost, 10 models ensemble\n- catboost, 10 models ensemble\n- keras, 10 models ensemble\n3. What library is the best in this problem?\n4. Build ensemble (averaging)\n","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-08-28T16:35:53.102683Z","iopub.execute_input":"2022-08-28T16:35:53.103250Z","iopub.status.idle":"2022-08-28T16:35:53.160203Z","shell.execute_reply.started":"2022-08-28T16:35:53.103224Z","shell.execute_reply":"2022-08-28T16:35:53.159220Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"numeric_columns = [i for i, j in zip(train_data.columns, train_data.dtypes) if j in [np.int64, np.float64] and i not in ['SalePrice', 'Id']]\nx_train = train_data[numeric_columns].fillna(-1)\nx_test = test_data[numeric_columns].fillna(-1)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T16:35:53.162146Z","iopub.execute_input":"2022-08-28T16:35:53.162479Z","iopub.status.idle":"2022-08-28T16:35:53.179481Z","shell.execute_reply.started":"2022-08-28T16:35:53.162446Z","shell.execute_reply":"2022-08-28T16:35:53.178105Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"y_train = np.log(train_data['SalePrice'])","metadata":{"execution":{"iopub.status.busy":"2022-08-28T16:35:53.181474Z","iopub.execute_input":"2022-08-28T16:35:53.182396Z","iopub.status.idle":"2022-08-28T16:35:53.188546Z","shell.execute_reply.started":"2022-08-28T16:35:53.182359Z","shell.execute_reply":"2022-08-28T16:35:53.187542Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def rmse(a, b):\n    return ((a - b) ** 2).mean() ** 0.5","metadata":{"execution":{"iopub.status.busy":"2022-08-28T16:35:53.191517Z","iopub.execute_input":"2022-08-28T16:35:53.192365Z","iopub.status.idle":"2022-08-28T16:35:53.198550Z","shell.execute_reply.started":"2022-08-28T16:35:53.192329Z","shell.execute_reply":"2022-08-28T16:35:53.197566Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"metrics = []","metadata":{"execution":{"iopub.status.busy":"2022-08-22T15:58:17.580920Z","iopub.execute_input":"2022-08-22T15:58:17.581670Z","iopub.status.idle":"2022-08-22T15:58:17.584827Z","shell.execute_reply.started":"2022-08-22T15:58:17.581640Z","shell.execute_reply":"2022-08-22T15:58:17.584175Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Gradient Boosting: sklearn\n\n(from academy's presentation)\n\nPros:\n- simple\n- feature importances\n- out of box\n\nCons:\n- many parameters\n- big and slow\n- custom loss implementation is not simple","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\nK = 10\n\nrmse_tr_sklearn = []\nrmse_val_sklearn = []\n\npreds_tr_sklearn = []\npreds_val_sklearn = []\n\nfor k in tqdm(range(K)):\n    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, shuffle=True, random_state=k)\n\n    model = GradientBoostingRegressor().fit(x_tr, y_tr)\n    \n    preds_tr = model.predict(x_tr)\n    preds_val = model.predict(x_val)\n\n    preds_tr_sklearn.append(preds_tr)\n    preds_val_sklearn.append(preds_val)\n    \n    rmse_tr_sklearn.append(rmse(preds_tr, y_tr))\n    rmse_val_sklearn.append(rmse(preds_val, y_val))\n    \nmetrics = []\nmetrics.append({'RMSE for sklearn train' : np.mean(rmse_tr_sklearn)})\nmetrics.append({'RMSE for sklearn val' : np.mean(rmse_val_sklearn)})\n\nmetrics","metadata":{"execution":{"iopub.status.busy":"2022-08-22T15:58:19.277463Z","iopub.execute_input":"2022-08-22T15:58:19.279021Z","iopub.status.idle":"2022-08-22T15:58:23.477351Z","shell.execute_reply.started":"2022-08-22T15:58:19.278970Z","shell.execute_reply":"2022-08-22T15:58:23.476321Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model_sklearn = GradientBoostingRegressor().fit(x_train, y_train)\ny_pred_sklearn = model_sklearn.predict(x_test)\nsubmit1 = pd.DataFrame()\nsubmit1['Id'] = test_data['Id']\nsubmit1['SalePrice'] = np.exp(y_pred_sklearn)\n\nsubmit1.to_csv('/kaggle/working/gb_sklearn_default.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T16:36:40.239437Z","iopub.execute_input":"2022-08-22T16:36:40.240287Z","iopub.status.idle":"2022-08-22T16:36:40.776353Z","shell.execute_reply.started":"2022-08-22T16:36:40.240254Z","shell.execute_reply":"2022-08-22T16:36:40.775674Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"public score of sklearn GB: 0.13672","metadata":{}},{"cell_type":"markdown","source":"Gradient Boosting: LightGBM\n\n(from academy's presentation)\n\nPros:\n- small fast\n- feature importances\n- out of box\n- simple implementation for custom loss\n\nCons:\n- too many parameters with synonyms\n- gigantic API\n- GPU support hard","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgbm\n\nrmse_tr_lgbm = []\nrmse_val_lgbm = []\n\npreds_tr_lgbm = []\npreds_val_lgbm = []\n\nfor k in tqdm(range(K)):\n    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, shuffle=True, random_state=k)\n\n    model = lgbm.LGBMRegressor().fit(x_tr, y_tr)\n    \n    preds_tr = model.predict(x_tr)\n    preds_val = model.predict(x_val)\n\n    preds_tr_lgbm.append(preds_tr)\n    preds_val_lgbm.append(preds_val)\n    \n    rmse_tr_lgbm.append(rmse(preds_tr, y_tr))\n    rmse_val_lgbm.append(rmse(preds_val, y_val))\n    \nmetrics.append({'RMSE for lgbm train' : np.mean(rmse_tr_lgbm)})\nmetrics.append({'RMSE for lgbm val' : np.mean(rmse_val_lgbm)})\n\nmetrics","metadata":{"execution":{"iopub.status.busy":"2022-08-22T15:58:25.856953Z","iopub.execute_input":"2022-08-22T15:58:25.857289Z","iopub.status.idle":"2022-08-22T15:58:28.073257Z","shell.execute_reply.started":"2022-08-22T15:58:25.857261Z","shell.execute_reply":"2022-08-22T15:58:28.072552Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model_lgb = lgbm.LGBMRegressor().fit(x_train, y_train)\ny_pred_lgb = model_lgb.predict(x_test)\nsubmit2 = pd.DataFrame()\nsubmit2['Id'] = test_data['Id']\nsubmit2['SalePrice'] = np.exp(y_pred_lgb)\n\nsubmit2.to_csv('/kaggle/working/lgb_default.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T16:37:35.457593Z","iopub.execute_input":"2022-08-22T16:37:35.457942Z","iopub.status.idle":"2022-08-22T16:37:35.624812Z","shell.execute_reply.started":"2022-08-22T16:37:35.457915Z","shell.execute_reply":"2022-08-22T16:37:35.623835Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"public score of sklearn LGB: 0.14099","metadata":{}},{"cell_type":"markdown","source":"Gradient Boosting: XGBoost\n\n(from academy's presentation)\n\nPros:\n- simple use\n- small fast\n- feature importances\n- out of box GPU support\n- simple implementation for custom loss\n\nCons:\n- many parameters\n- gigantic API","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\n\nrmse_tr_xgb = []\nrmse_val_xgb = []\n\npreds_tr_xgb = []\npreds_val_xgb = []\n\nfor k in tqdm(range(K)):\n    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, shuffle=True, random_state=k)\n\n    model = XGBRegressor().fit(x_tr, y_tr)\n    \n    preds_tr = model.predict(x_tr)\n    preds_val = model.predict(x_val)\n\n    preds_tr_xgb.append(preds_tr)\n    preds_val_xgb.append(preds_val)\n    \n    rmse_tr_xgb.append(rmse(preds_tr, y_tr))\n    rmse_val_xgb.append(rmse(preds_val, y_val))\n    \nmetrics.append({'RMSE for xgb train' : np.mean(rmse_tr_xgb)})\nmetrics.append({'RMSE for xgb val' : np.mean(rmse_val_xgb)})\n\nmetrics","metadata":{"execution":{"iopub.status.busy":"2022-08-22T15:58:29.888006Z","iopub.execute_input":"2022-08-22T15:58:29.888329Z","iopub.status.idle":"2022-08-22T15:58:33.460264Z","shell.execute_reply.started":"2022-08-22T15:58:29.888302Z","shell.execute_reply":"2022-08-22T15:58:33.459417Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model_xgb = XGBRegressor().fit(x_train, y_train)\ny_pred_xgb = model_xgb.predict(x_test)\nsubmit3 = pd.DataFrame()\nsubmit3['Id'] = test_data['Id']\nsubmit3['SalePrice'] = np.exp(y_pred_xgb)\n\nsubmit3.to_csv('/kaggle/working/xgb_default.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T16:38:39.101903Z","iopub.execute_input":"2022-08-22T16:38:39.102555Z","iopub.status.idle":"2022-08-22T16:38:39.477881Z","shell.execute_reply.started":"2022-08-22T16:38:39.102514Z","shell.execute_reply":"2022-08-22T16:38:39.476784Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"public score of sklearn XGB: 0.15080","metadata":{}},{"cell_type":"markdown","source":"Gradient Boosting: CatBoost\n\n(from academy's presentation)\n\nPros:\n- optimized for categories\n- accurate and fast\n- small fast\n- feature importances\n- out of box\n\nCons:\n- problems with custom loss","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostRegressor\n\nrmse_tr_cat = []\nrmse_val_cat = []\n\npreds_tr_cat = []\npreds_val_cat = []\n\nfor k in tqdm(range(K)):\n    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, shuffle=True, random_state=k)\n\n    model = CatBoostRegressor(verbose=False).fit(x_tr, y_tr)\n    \n    preds_tr = model.predict(x_tr)\n    preds_val = model.predict(x_val)\n\n    preds_tr_cat.append(preds_tr)\n    preds_val_cat.append(preds_val)\n    \n    rmse_tr_cat.append(rmse(preds_tr, y_tr))\n    rmse_val_cat.append(rmse(preds_val, y_val))\n    \nmetrics.append({'RMSE for cat train' : np.mean(rmse_tr_cat)})\nmetrics.append({'RMSE for cat val' : np.mean(rmse_val_cat)})\n\nmetrics","metadata":{"execution":{"iopub.status.busy":"2022-08-22T15:58:35.714110Z","iopub.execute_input":"2022-08-22T15:58:35.714836Z","iopub.status.idle":"2022-08-22T15:58:52.792636Z","shell.execute_reply.started":"2022-08-22T15:58:35.714789Z","shell.execute_reply":"2022-08-22T15:58:52.791559Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model_cat = CatBoostRegressor(verbose=False).fit(x_train, y_train)\ny_pred_cat = model_lgb.predict(x_test)\nsubmit4 = pd.DataFrame()\nsubmit4['Id'] = test_data['Id']\nsubmit4['SalePrice'] = np.exp(y_pred_cat)\n\nsubmit4.to_csv('/kaggle/working/catboost_default.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T16:39:38.620461Z","iopub.execute_input":"2022-08-22T16:39:38.621285Z","iopub.status.idle":"2022-08-22T16:39:40.499695Z","shell.execute_reply.started":"2022-08-22T16:39:38.621253Z","shell.execute_reply":"2022-08-22T16:39:40.498902Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"public score of sklearn XGB: 0.14099","metadata":{}},{"cell_type":"markdown","source":"Gradient Boosting: TensorFlow\n\n(from academy's presentation)\n\nPros:\n- simple use\n- small fast\n- feature importances\n- out of box GPU\n- simple implementation for custom loss\n- good documentation\n\nCons:\n- gigantic docs","metadata":{}},{"cell_type":"code","source":"# !pip install tensorflow_decision_forests\nimport tensorflow_decision_forests as tfdf\n\nrmse_tr_keras = []\nrmse_val_keras = []\n\npreds_tr_keras = []\npreds_val_keras = []\n\nfor k in tqdm(range(K)):\n    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, shuffle=True, random_state=k)\n    tr = pd.concat([x_tr, y_tr], axis=1)\n    tf_tr = tfdf.keras.pd_dataframe_to_tf_dataset(tr, label='SalePrice', task=tfdf.keras.Task.REGRESSION)\n    \n    model = tfdf.keras.GradientBoostedTreesModel(task=tfdf.keras.Task.REGRESSION, verbose=0)\n    model.fit(x=tf_tr)\n    \n    preds_tr = model.predict(tfdf.keras.pd_dataframe_to_tf_dataset(x_tr, task=tfdf.keras.Task.REGRESSION))\n    preds_val = model.predict(tfdf.keras.pd_dataframe_to_tf_dataset(x_val, task=tfdf.keras.Task.REGRESSION))\n    \n    preds_tr = np.array([pred_tr_el for pred_tr in preds_tr for pred_tr_el in pred_tr])\n    preds_val = np.array([pred_val_el for pred_val in preds_val for pred_val_el in pred_val])\n        \n    preds_tr_keras.append(preds_tr)\n    preds_val_keras.append(preds_val)\n    \n    rmse_tr_keras.append(rmse(preds_tr, y_tr))\n    rmse_val_keras.append(rmse(preds_val, y_val))\n    \nmetrics.append({'RMSE for keras train' : np.mean(rmse_tr_keras)})\nmetrics.append({'RMSE for keras val' : np.mean(rmse_val_keras)})\n\nmetrics","metadata":{"execution":{"iopub.status.busy":"2022-08-22T16:40:27.563665Z","iopub.execute_input":"2022-08-22T16:40:27.564381Z","iopub.status.idle":"2022-08-22T16:40:53.447740Z","shell.execute_reply.started":"2022-08-22T16:40:27.564349Z","shell.execute_reply":"2022-08-22T16:40:53.446773Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"train = pd.concat([x_train, y_train], axis=1)\ntf_train = tfdf.keras.pd_dataframe_to_tf_dataset(train, label='SalePrice', task=tfdf.keras.Task.REGRESSION)\nmodel_keras = tfdf.keras.GradientBoostedTreesModel(task=tfdf.keras.Task.REGRESSION, verbose=0)\nmodel_keras.fit(x=tf_train)\ny_pred_keras = model.predict(tfdf.keras.pd_dataframe_to_tf_dataset(x_test, task=tfdf.keras.Task.REGRESSION))\ny_pred_keras = np.array([preds_keras_el for pred_keras in y_pred_keras for preds_keras_el in pred_keras])   \nsubmit5 = pd.DataFrame()\nsubmit5['Id'] = test_data['Id']\nsubmit5['SalePrice'] = np.exp(y_pred_keras)\n\nsubmit5.to_csv('/kaggle/working/keras_gb_default.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T16:43:10.259252Z","iopub.execute_input":"2022-08-22T16:43:10.259668Z","iopub.status.idle":"2022-08-22T16:43:13.627675Z","shell.execute_reply.started":"2022-08-22T16:43:10.259639Z","shell.execute_reply":"2022-08-22T16:43:13.626670Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"public score of tensorflow: 0.14689","metadata":{}},{"cell_type":"code","source":"sorted(metrics, key=lambda x: list(x.values())[0])","metadata":{"execution":{"iopub.status.busy":"2022-08-22T16:10:42.554323Z","iopub.execute_input":"2022-08-22T16:10:42.554670Z","iopub.status.idle":"2022-08-22T16:10:42.561767Z","shell.execute_reply.started":"2022-08-22T16:10:42.554644Z","shell.execute_reply":"2022-08-22T16:10:42.560679Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"Looking at the validation scores, the best result brought catboost\nLooking at the public score on test data, the order from the best to worse is:\n1. sklearn\n2. lgb and catboost\n3. keras\n4. xgb","metadata":{}},{"cell_type":"code","source":"y_pred_sklearn = []\ny_pred_lgb = []\ny_pred_xgb = []\ny_pred_cat = []\ny_pred_keras = []\n    \nmodel_sklearn = GradientBoostingRegressor().fit(x_train, y_train)\ny_pred_sklearn.append(model_sklearn.predict(x_test))\n\nmodel_lgb = lgbm.LGBMRegressor().fit(x_train, y_train)\ny_pred_lgb.append(model_lgb.predict(x_test))\n\nmodel_xgb = XGBRegressor().fit(x_train, y_train)\ny_pred_xgb.append(model_xgb.predict(x_test))\n\nmodel_cat = CatBoostRegressor(verbose=False).fit(x_train, y_train)\ny_pred_cat.append(model_cat.predict(x_test))\n\ntrain = pd.concat([x_train, y_train], axis=1)\ntf_train = tfdf.keras.pd_dataframe_to_tf_dataset(train, label='SalePrice', task=tfdf.keras.Task.REGRESSION)\nmodel_keras = tfdf.keras.GradientBoostedTreesModel(task=tfdf.keras.Task.REGRESSION, verbose=0)\nmodel_keras.fit(x=tf_train)\npreds_keras = model.predict(tfdf.keras.pd_dataframe_to_tf_dataset(x_test, task=tfdf.keras.Task.REGRESSION))\ny_pred_keras.append(np.array([preds_keras_el for pred_keras in preds_keras for preds_keras_el in pred_keras]))    ","metadata":{"execution":{"iopub.status.busy":"2022-08-22T16:23:19.533579Z","iopub.execute_input":"2022-08-22T16:23:19.533967Z","iopub.status.idle":"2022-08-22T16:23:24.935867Z","shell.execute_reply.started":"2022-08-22T16:23:19.533936Z","shell.execute_reply":"2022-08-22T16:23:24.935005Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"y_pred_ensemble = np.mean([y_pred_sklearn, y_pred_lgb, y_pred_xgb, y_pred_cat, y_pred_keras], axis=0)\ny_pred_ensemble","metadata":{"execution":{"iopub.status.busy":"2022-08-22T16:43:53.459108Z","iopub.execute_input":"2022-08-22T16:43:53.459482Z","iopub.status.idle":"2022-08-22T16:43:53.466955Z","shell.execute_reply.started":"2022-08-22T16:43:53.459447Z","shell.execute_reply":"2022-08-22T16:43:53.465936Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"submit = pd.DataFrame()\nsubmit['Id'] = test_data['Id']\nsubmit['SalePrice'] = np.exp(y_pred_ensemble)\n\nsubmit","metadata":{"execution":{"iopub.status.busy":"2022-08-22T16:26:31.099205Z","iopub.execute_input":"2022-08-22T16:26:31.099538Z","iopub.status.idle":"2022-08-22T16:26:31.116778Z","shell.execute_reply.started":"2022-08-22T16:26:31.099512Z","shell.execute_reply":"2022-08-22T16:26:31.115790Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"submit.to_csv('/kaggle/working/diff_gb_models_ensemble.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T16:27:16.126636Z","iopub.execute_input":"2022-08-22T16:27:16.127007Z","iopub.status.idle":"2022-08-22T16:27:16.139471Z","shell.execute_reply.started":"2022-08-22T16:27:16.126978Z","shell.execute_reply":"2022-08-22T16:27:16.138682Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"public score of different GB implementations ensemble: 0.13505\n\nwhich is better then any other implementation on its own","metadata":{}}]}